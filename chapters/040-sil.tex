% !TEX root = ../phd-thesis.tex

\chapter{A Comparison of Program Logics}\label{ch:sil}
In this chapter, we consider three known triple-based program logics, namely Hoare Logic (HL), Incorrectness Logic (IL) and Necessary Conditions (NC). We characterize their validity conditions in term of over or under-approximation of forward and backward semantics. First, this allows us to identify the absence of one combination, and thus to define a new program logic, called Sufficient Incorrectness Logic (SIL), for it. Second, this guides a thorough comparison of the four validity conditions, highlighting analogies and differences between them.

The content of this chapter is based on~\cite{ABGL24}.

\section{Taxonomy}
\begin{figure}[t]
	\centering
	\begin{tabular}{c|ccc}
		                   & Forward                   &                                        & Backward                                            \\[3pt]
		\hline             &                           &                                        &                                                     \\[-5pt]
		\quad Over \quad\  & \quad Hoare Logic         & $\xleftrightarrow{\qquad\simeq\qquad}$ & Necessary Conditions                                \\[5pt]
		\quad Under\quad\  & \quad Incorrectness Logic &                                        & \textcolor{ACMBlue}{Sufficient Incorrectness Logic}
	\end{tabular}
	\caption{The taxonomy of triple-based logics. They are sorted depending on whether they use forward or backward semantics and over or under-approximation. HL and NC are equivalent ($\simeq$). SIL is the new logic introduced here.}
	\label{fig:sil:taxonomy}
\end{figure}

As discussed in Sections~\ref{sec:bg:hl} and \ref{sec:bg:il}, the validity conditions of HL and IL are defined as over and under-approximation of the forward semantics $\fwsem{\cdot}$. However, other program logics cannot be naturally described in terms of $\fwsem{\cdot}$. To this end, we consider a backward semantics $\bwsem{\cdot}$ defined as the opposite relation of the forward semantics, that is

\begin{equation}
	\bwsem{\regr} \sigma' \eqdef \{ \sigma \mid \sigma' \in \fwsem{\regr} \sigma \} \label{eq:sil:bwsem-definition}
\end{equation}

\noindent or, equivalently,

\begin{equation}
	\sigma \in \bwsem{\regr} \sigma' \iff \sigma' \in \fwsem{\regr} \sigma  \label{eq:sil:bwsem-sigma-sigma'}
\end{equation}

\noindent and we lift this definition of backward semantics to set of states by union.
Intuitively, the forward semantics $\fwsem{\regr} P$ denotes the set of all possible output states of $\regr$ when execution starts from a state in $P$ (and $\regr$ terminates).
Instead, the backward semantics $\bwsem{\regr} Q$ denotes the set of all input states that can lead to a state in $Q$.

The backward semantics can also be characterized compositionally, similarly to the forward one:

\begin{lemma}\label{lmm:sil:bwsem-calculus}
	For any regular commands $\regr,\regr_1,\regr_2\in \Reg$, the following equalities hold:
	\[
	\bwsem{\regr_1; \regr_2} = \bwsem{\regr_1} \circ \bwsem{\regr_2} \qquad\qquad
	\bwsem{\regr_1 \regplus \regr_2} = \bwsem{\regr_1} \cup \bwsem{\regr_2} \qquad\qquad
	\bwsem{{\regr^\kstar}} = \bigcup\limits_{n \ge 0} \bwsem{\regr}^n
	\]
\end{lemma}

Using $\bwsem{\cdot}$, we characterize NC with the validity condition $\bwsem{\regr} Q \subseteq P$:

\begin{prop}[NC as backward over-approximation]\label{prop:sil:nc}
	Given a postcondition $Q$ for the program $\regr$, any possible necessary precondition $\underline{P}$ for $Q$ satisfies
	\[
	\bwsem{\regr} Q \subseteq \underline{P}
	\]
\end{prop}

Note that this is not a new understanding of NC (it was already hinted in the work that introduced them, and an analogous characterization appeared in~\cite[ยง6.3]{ZK22} in terms of weakest precondition), but the explicit use of the backward semantics in our contest enables a more streamlined comparison with other logics in Section~\ref{sec:sil:comparison}.

We organize the validity conditions of HL, IL and NC in the taxonomy in Figure~\ref{fig:sil:taxonomy}. We classify logics depending on (1) whether the condition is expressed in terms of forward or backward semantics and (2) whether it is an over or an under-approximation.
This naturally sparks the question on what does the backward under-approximation condition mean and whether a logic for it has been developed.

\paragraph{Backward under-approximation and Lisbon Triples}
At POPL'19 in Lisbon, D. Dreyer and R. Jung suggested that P. O'Hearn should look at bug-finding in terms of a logic for proving the presence of faults (as reported in~\cite{OHearn20,ZDS23}).
However, the proposed model of triples did not fit well with a key feature of Pulse, a bug-catching tool developed mainly by J. Villard at Meta, namely its ability to drop the analysis of some program paths, for which IL provides a sound logical foundation instead.
The idea of such ``Lisbon'' triples is that \emph{for any initial state satisfying the pre, there exists some execution trace leading to a final state satisfying the post} and it can be dated back to Hoare's calculus of possible correctness~\cite{Hoare78}, even if no form of approximation was considered there.
Lisbon triples were then briefly discussed in~\cite[\S 5]{MOH21} and \cite[\S 3.2]{LRVBDO22} under the name \emph{backwards under-approximate triples}. They were also one of the motivations for OL~\cite{ZDS23} and are identified as certain OL triple.

Ideally, given an incorrectness specification, the goal of backward under-approximation would be to report to programmers all dangerous input states that lead to bugs.
However, all the above proposals are designed according to the forward semantics of programs and thus are best suited to infer postconditions starting from some given precondition: in general, their backward analysis may require the instantiation of their consequence rules with some ingenious guess.
To tackle this issue, we introduce Sufficient Incorrectness Logic (SIL) as a proof system for Lisbon triples with backward\hyp{}oriented rules.

\begin{figure}
	\centering
	\begin{tabular}{c|c@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c}
		Logic                    &
		HL \cite{Hoare69}        &
		IL \cite{OHearn20}       &
		NC \cite{CCL11}          &
		OL \cite{ZDS23}          &
		SIL
		\\[2pt] \hline &&&&& \\[-10pt]
		Triples                  &
		$\hltriple{P}{\regr}{Q}$ &
		$\iltriple{P}{\regr}{Q}$ &
		$\nctriple{P}{\regr}{Q}$ &
		$\oltriple{P}{\regr}{Q}$ &
		$\siltriple{P}{\regr}{Q}$
	\end{tabular}
	\caption{Summary of the notation for different program logics}
	\label{fig:sil:notation-summary}
\end{figure}

Since in this chapter we deal with different kinds of program logics, a summary of the notation for the various triples is reported in Figure~\ref{fig:sil:notation-summary}.

\section{Sufficient Incorrectness Logic}
Sufficient incorrectness conditions identify the source of incorrectness and provide programmers with evidence of the inputs that can cause the errors.
The SIL triple
\[
\siltriple{P}{\regr}{Q}
\]
asserts that ``\emph{all states in $P$ have at least one execution leading to a state in $Q$}'', which can be summarized with the validity condition
\[
\bwsem{\regr} Q \supseteq P \text{.}
\]
Please note that, in the presence of nondeterminism, states in $P$ are required to have one execution leading to $Q$, not necessarily all of them.
We make this point evident by the following proposition.

\begin{prop}[Characterization of SIL validity]\label{prop:sil:validity-characterization}
	For any $\regr \in \Reg$, $P, Q \subseteq \Sigma$ we have
	\[
	\bwsem{\regr} Q \supseteq P \iff \forall \sigma \in P \sdot \exists \sigma' \in Q \sdot \sigma' \in \fwsem{\regr} \sigma
	\]
\end{prop}

A convenient way to exploit SIL is to assume that the analysis takes as input the incorrectness specification $Q$, i.e., the set of erroneous final states. Then, any valid SIL triple $\siltriple{P}{\regr}{Q}$ yields a precondition which surely captures erroneous executions. In this sense, $P$ gives a sufficient condition for incorrectness. This is dual to the interpretation of IL where, for a given precondition $P$, any IL triple $\iltriple{P}{\regr}{Q}$ yields a set $Q$ of final states which are for sure
reachable, so that any error state in $Q$ is a true bug reachable from some input in $P$.
We show that SIL and IL triples differ via a simple example.

\begin{example}\label{ex:sil:sil-vs-il}
	Let us consider the simple deterministic program $\regr 42$, already used in~\cite{OHearn20} to show the essence of IL triples:
	\begin{minted}{C}
if (x is even) {
	if (y is odd) {
		z := 42;
	}
}
// assert(z != 42)
	\end{minted}
	We assume that $Q_{42} \eqdef (z = 42)$ denotes the set of erroneous states.
	Any SIL triple provides a sufficient condition for the input state that causes the error. For instance, in SIL (but not with IL) we can prove the triple $\siltriple{\text{odd}(y) \wedge \text{even}(x)}{\regr 42}{Q_{42}}$ stating that any state where $x$ is even and $y$ is odd will lead to the error (i.e., $z=42$).
	In IL, but \emph{not} in SIL, one can prove that some errors can be reached even when we start in a safe state. For instance, $\iltriple{z=11}{\regr 42}{Q_{42} \wedge \text{odd}(y) \wedge \text{even}(x)}$ is a valid IL but not in SIL. In fact, it is not true that for any state where $z=11$ the program $\regr 42$ will reach an error, e.g., when we start with $z \mapsto 11, x \mapsto 0, y \mapsto 0$.
\end{example}

Sufficient incorrectness preconditions are extremely valuable to programmers: by pointing out the sources of errors, they serve as a starting point to scope down debugging, fuzzing, and testing. Moreover, it is known that, contrary to IL and its extensions, backward under\hyp{}approximation can expose manifest errors~\cite[ยง3.2]{LRVBDO22}: an error $Q$ is manifest if and only if the SIL triple $\siltriple{\true}{\regr}{Q}$ is valid. Intuitively, an error is manifest if it happens regardless of the context, and experimentally it has been observed that manifest errors are likely to be fixed when reported~\cite[ยง5]{LRVBDO22}.
Moreover, IL and SIL share the possibility to drop disjuncts, one of the leading factors for the introduction of IL to increase scalability and make bug\hyp{}finding effective: the key difference is that IL drops disjuncts in the post, while SIL in the pre.

\subsection{Proof System}\label{sec:sil:sil-rules}

\begin{figure*}[t]
	\centering
	\begin{framed}
		\(
		\begin{array}{cc}
			\infer[\silrule{atom}]
			{\siltriple{\bwsem{\regc}Q}{\regc}{Q}}
			{}
			\quad                        &
			\infer[\silrule{cons}]
			{\siltriple{P}{\regr}{Q}}
			{P \subseteq P'              & \siltriple{P'}{\regr}{Q'}    & Q' \subseteq Q}
			\\[7.5pt]
			\infer[\silrule{seq}]
			{\siltriple{P}{\regr_1;\regr_2}{Q}}
			{\siltriple{P}{\regr_1}{R}   & \siltriple{R}{\regr_2}{Q}}
			\qquad                       &
			\infer[\silrule{choice}]
			{\siltriple{P_1 \cup P_2}{\regr_1 \regplus \regr_2}{Q}}
			{\siltriple{P_1}{\regr_1}{Q} & \siltriple{P_2}{\regr_2}{Q}}
			\\[7.5pt]
			\infer[\silrule{iter}]
			{\siltriple{\bigcup\limits_{n \ge 0} Q_n}{\regr^\kstar}{Q_0}}
			{\forall n \ge 0 \sdot \siltriple{Q_{n+1}}{\regr}{Q_n}}
		\end{array}
		\)\\
		\vspace{0.3em}
		\hrulefill \\
		\vspace{-2.5ex}\hrulefill
		\vspace{-0.2em}
		\begin{center}
			\small Additional rules
		\end{center}
		\(
		\begin{array}{cc}
			\infer[\silrule{empty}]
			{\siltriple{\emptyset}{\regr}{Q}}
			{}
			\qquad                       &
			\infer[\silrule{iter0}]
			{\siltriple{Q}{\regr^\kstar}{Q}}
			{}
			\\[7.5pt]
			\infer[\silrule{unroll}]
			{\siltriple{P}{\regr^\kstar}{Q}}
			{\siltriple{P}{\regr^\kstar; \regr}{Q}}
			\qquad                       &
			\infer[\silrule{disj}]
			{\siltriple{P_1 \cup P_2}{\regr}{Q_1 \cup Q_2}}
			{\siltriple{P_1}{\regr}{Q_1} & \siltriple{P_2}{\regr}{Q_2} }
		\end{array}
		\)
	\end{framed}
	\caption{Sufficient Incorrectness Logic}\label{fig:sil:sil-rules}
\end{figure*}

The inference rules for SIL are in Figure~\ref{fig:sil:sil-rules}. The top five rules form a minimal, correct and complete proof system.
Atomic commands are handled by \silrule{atom}, which exploits the backward semantics.
Rule \silrule{seq} is standard.
Rule \silrule{choice} is reminiscent of the equation for conditionals in the calculus of possible correctness \cite{Hoare78}. If all states in $P_i$ have an execution of $\regr_i$ ending in $Q$, they can choose nondeterministically to execute $\regr_i$ in $\regr_1 \regplus \regr_2$, ending in $Q$.
For iteration, for each $n \ge 0$ we find inductively the precondition $Q_n$ of executing $\regr$ exactly $n$ times. The precondition of the whole $\regr^{\kstar}$ is then the union of all the $Q_n$, as formalized by rule \silrule{iter}, which first appeared in \cite[\S 5]{MOH21}.
The consequence rule \silrule{cons} enables the under-approximation of the precondition and it follows from the validity condition. If all the states in $P'$ have an execution leading to a state in $Q'$, then any subset $P$ of $P'$ will lead to $Q'$ as well. Similarly, every superset $Q$ of $Q'$ is reachable by executions starting in $P$.

The SIL proof system is both correct and complete. Correctness can be proved by induction on the derivation tree of a triple. Intuitively, if the premises of a rule are valid, then its consequence is valid as well, as we briefly observed in the previous section. To prove completeness, we rely on the fact that rules other than \silrule{cons} are exact, that is, if their premises satisfy the equality $\bwsem{\regr} Q = P$, their conclusion does as well. Using this, we prove the triple $\siltriple{\bwsem{\regr}Q}{\regr}{Q}$ for any $\regr$ and $Q$. Then we conclude using \silrule{cons} to get a proof of $\siltriple{P}{\regr}{Q}$ for any $P \subseteq \bwsem{\regr}Q$.

\begin{theorem}[SIL is sound and complete]\label{thm:sil:sil-sound-complete}
	A SIL triple is provable if and only if it is valid:
	\[
	\vdash\siltriple{P}{\regr}{Q} \iff \vDash\siltriple{P}{\regr}{Q}
	\]
\end{theorem}

\paragraph*{Additional Rules for Program Analysis}
The above set of five rules is deliberately minimal: if we remove any rule, SIL is no longer complete. However, there are other valid rules, not derivable from those five, that can be useful in practice. Some of them are at the bottom of Figure~\ref{fig:sil:sil-rules}.

Rule \silrule{empty} is used to drop paths backward, just like IL can drop them forward (an analogous axiom $\iltriple{P}{\regr}{\emptyset}$ is valid for IL). Particularly, this allows to ignore one of the branches of \silrule{choice}, or to stop the backward iteration of \silrule{iter} without covering all the iterations. An example of such an application is the derived rule \silrule{iter0}, which corresponds to not entering the iteration at all. It can be proved from rules \silrule{iter} and \silrule{empty} by taking $Q_0 = Q$ and $Q_n = \emptyset$ for $n \ge 1$. It subsumes HL's rule \hlrule{iter}, which is based on loop invariants: those are a correct but not complete reasoning tool for under\hyp{}approximation~\cite{OHearn20}.
Rule \silrule{unroll} allows to unroll a loop once. Subsequent applications of this rule allow to simulate (backward) a finite number of iterations, and then rule \silrule{iter0} can be used to ignore the remaining ones. This is on par with IL ability to unroll a loop a finite number of times to find some post, for which analogous rules are valid~\cite{OHearn20,MOH21}.
Rule \silrule{disj} allows to split the analysis and join the results, just like HL and IL. However, while a corresponding rule \hlrule{conj} which perform intersection is sound for HL, it is unsound for both IL and SIL (see Example~\ref{ex:sil:under-approx-no-strongest}).

\begin{example}\label{ex:sil:derivation}
	Let us consider the program ``loop0'' from~\cite[\S 6.1]{OHearn20}:

	\begin{minted}{C}
x := 0;
n := nondet();
while(n > 0) {
	x := x + n;
	n := nondet();
}
// assert(x != 2000000)
	\end{minted}

	We can translate it in the syntax of regular commands by letting
	\begin{align*}
		\regr_w         & \eqdef \code{(n > 0)?; x := x + n; n := nondet()}                         \\
		\mathsf{rloop0} & \eqdef \code{x := 0; n := nondet(); }(\regr_w)^{\kstar}; \code{(n <= 0)?}
	\end{align*}
	Final error states are those in $Q_{2M} \eqdef (x = 2 000 000)$.

	\begin{figure}[t]
		\centering
		\footnotesize
		\[
		\infer[]
		{(*)}
		{
			\infer[\silrule{seq}]{\siltriple{T_{2M}}{\regr_w^{\kstar}; \code{(n <= 0)?}}{Q_{2M}}}{
				\infer[\silrule{unroll}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{R_{2M}}}{
					\infer[\silrule{seq}]{\siltriple{T_{2M}}{\regr_w^{\kstar}; \regr_w}{R_{2M}}}{
						\infer[\silrule{iter0}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{T_{2M}}}{}
						&
						\infer{\siltriple{T_{2M}}{\regr_w}{R_{2M}}}{\vdots}
					}
				}
				&
				\infer[\silrule{atom}]{\siltriple{R_{2M}}{\code{(n <= 0)?}}{Q_{2M}}}{}
			}
		}
		\]

		\[
		\infer[\silrule{seq}]
		{\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}}
		{
			\infer[\silrule{seq}]{\siltriple{\true}{\code{x := 0; n := nondet()}}{T_{2M}}}{
				\infer[\silrule{atom}]{\siltriple{\true}{\code{x := 0}}{x \le 2000000}}{}
				&
				\infer[\silrule{atom}]{\siltriple{x \le 2000000}{\code{n := nondet()}}{T_{2M}}}{}
			}
			&
			(*)
		}
		\]
		\caption{Derivation of the SIL triple $\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}$ for Example~\ref{ex:sil:derivation}.}
		\label{fig:sil:example-derivation}
	\end{figure}

	To prove a triple for $\mathsf{rloop0}$, we have to perform at least one iteration, and we do so using \silrule{unroll}.
	We let $R_{2M} \eqdef (x = 2000000 \land n \le 0)$ and $T_{2M} \eqdef (x + n = 2000000 \land n > 0)$. It is straightforward to prove $\siltriple{T_{2M}}{\regr_w}{R_{2M}}$ via \silrule{seq} and \silrule{atom}. Given this triple, we can unroll the loop once and prove the same triple for $\regr_w^{\kstar}$:
	\[
	\infer[\silrule{unroll}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{R_{2M}}}{
		\infer[\silrule{seq}]{\siltriple{T_{2M}}{\regr_w^{\kstar}; \regr_w}{R_{2M}}}{
			\infer[\silrule{iter0}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{T_{2M}}}{}
			&
			\infer{\siltriple{T_{2M}}{\regr_w}{R_{2M}}}{\cdots}
		}
	}
	\]
	This is a property of under-approximation: a non-deterministic number of iterations can be under-approximated by a single iteration \cite[\S 6.1]{OHearn20}.
	With this triple for the loop, we can prove for the whole program the triple $\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}$ using \silrule{seq} and \silrule{atom}. The full derivation is in Figure~\ref{fig:sil:example-derivation}.

	Differently than IL, this triple highlights that any initial state can lead to an error: instead of reporting the presence of a true bug, we can report an initial state which causes the bug.
\end{example}

\section{Relations Among Logics}\label{sec:sil:comparison}
\todo[inline]{Check this whole section because rn is mid (also add some stuff for NC in the background and the appendix)}
Following the two-dimensional taxonomy in Figure~\ref{fig:sil:taxonomy}, we carry out an exhaustive comparison among the four validity conditions. While the duality between HL and IL was crystal clear since the introduction of IL, their relations with NC and SIL has never been explored. For reference, we summarize the validity of different kinds of triples below.

\begin{definition}\label{def:sil:validity}
	For any program $\regr$ and sets of states $P,Q$ we let the following:

	\smallskip
	\begin{tabular}{lclr}
		\textbf{HL triples:}  & $\hltriple{P}{\regr}{Q}$  & is valid if & $\fwsem{\regr} P \subseteq Q$; \\
		\textbf{IL triples:}  & $\iltriple{P}{\regr}{Q}$  & is valid if & $\fwsem{\regr} P \supseteq Q$; \\
		\textbf{NC triples:}  & $\nctriple{P}{\regr}{Q}$  & is valid if & $\bwsem{\regr} Q \subseteq P$; \\
		\textbf{SIL triples:} & $\siltriple{P}{\regr}{Q}$ & is valid if & $\bwsem{\regr} Q \supseteq P$.
	\end{tabular}
\end{definition}

Validity of HL and IL corresponds to the constraints $\fwsem{\regr} P \subseteq Q$ and $\fwsem{\regr} P \supseteq Q$, respectively. Therefore, their validity is expressed using the forward semantics. The difference between the two inequalities resides in the direction of the inclusion: the postcondition is an over-approximation of the forward semantics in HL, while it is an under-approximation in IL.
Dually, the validity condition for NC and SIL triples, $\bwsem{\regr} Q \subseteq P$ and $\bwsem{\regr} Q \supseteq P$ respectively. Note that we classify NC as an over-approximation because $P$ is a superset of the (backward) semantics applied to $Q$, and dually for SIL: we check the direction of the approximation on the ``target'' set of the condition (that is, $Q$ for forward and $P$ for backward semantics).

\subsection{Pairwise Comparison}
\subsubsection{NC and IL}
Sufficient preconditions are properties that imply Dijkstra's weakest liberal precondition~\cite{Dijkstra75}: $\overline{P}$ is sufficient for a postcondition $Q$ if and only if $\overline{P} \Rightarrow \wlp[\regr](Q)$, which in turn is equivalent to validity of the HL triple $\hltriple{\overline{P}}{\regr}{Q}$. Necessary and sufficient preconditions are dual, and so are IL and HL. Moreover, NC and IL enjoy the same consequence rule: both can strengthen the post and weaken the pre. While this suggests that there could be a relation between NC and IL, the following example shows this is not the case.

\begin{example}
	Let us consider the deterministic program $\regr 42$ of Example~\ref{ex:sil:sil-vs-il}, with $Q_{42} \eqdef (z=42)$.
	Let $Q'_{42} \eqdef (Q_{42} \wedge \text{odd}(y) \wedge \text{even}(x))$ and $P_{11} \eqdef (z = 11)$. We know from the previous example that $\iltriple{P_{11}}{\regr 42}{Q'_{42}}$ is a valid IL triple.
	However, we observe that the NC triple $\nctriple{P_{11}}{\regr 42}{Q'_{42}}$ is not valid because the state $\sigma$ such that $\sigma(x) = 0$, $\sigma(y) = 1$, $\sigma(z) = 10$ has an execution leading to $Q'_{42}$ but is not in $P_{11}$.
	Moreover, take for instance $\underline{P} = (\text{odd}(y) \land \text{even}(x))$, which makes the NC triple $\nctriple{\underline{P}}{\regr 42}{Q'_{42}}$ valid (any state \emph{not} satisfying $\underline{P}$ has either an even $y$ or an odd $x$, and those variables are not changed by the program). Then it is clear that $P_{11} \notimplies \underline{P}$. This shows that not only IL triples do not yield NC triples, but also that in general there are NC preconditions which are not implied by IL preconditions.

	Conversely, consider $\neg Q_{42} = (z \neq 42)$. While the NC triple $\nctriple{\true}{\regr 42}{\neg Q_{42}}$ is valid, the IL triple $\iltriple{\true}{\regr 42}{\neg Q_{42}}$ is not: for instance, the final state $\sigma'$ such that $\sigma'(x) = \sigma'(y) = \sigma'(z) = 11$ is not reachable from any initial state. It follows that the IL triple $\iltriple{P}{\regr 42}{\neg Q_{42}}$ is not valid for any $P$.
\end{example}

Given a valid NC triple $\nctriple{\underline{P}}{\regr}{Q}$ and a valid IL triple $\iltriple{P}{\regr}{Q}$, there are states satisfying both $P$ and $\underline{P}$, i.e., $P \cap \underline{P} \neq \emptyset$. However, in general neither $P \subseteq \underline{P}$ nor $\underline{P} \subseteq P$ hold. The difference between NC and IL is striking when we spell out their validity conditions using quantifiers: initial states are universally quantified in (NC$^{\forall}$)---\emph{all} initial states with a good run must satisfy the precondition---but they are existentially quantified in (IL$^{\exists}$).
\begin{align*}
	\forall \sigma' \in Q \sdot \forall \sigma\in \bwsem{\regr}\sigma' \sdot\sigma\in P
	\tag{NC$^{\forall}$} \\
	\forall \sigma' \in Q \sdot \exists \sigma\in \bwsem{\regr}\sigma' \sdot \sigma \in P
	\tag{IL$^{\exists}$}
\end{align*}

We observe that, whenever $\regr$ is reversible (i.e., $\fwsem{\regr}$ is injective) any valid IL triple is also a valid NC triple.

\subsubsection{NC and HL}
%\label{sec:nc-hl}
It turns out that NC is strongly connected to weakest liberal preconditions and thus to HL.
Let $Q$ be a correctness specification: a finite trace is in $\mathcal{T}(\sigma)$ if its final state satisfies $Q$ and in $\mathcal{E}(\sigma)$ otherwise.
In general, a necessary precondition has no relationship with $\wlp[\regr](Q)$. However, if we consider $\lnot Q$ instead of $Q$, we observe that ``erroneous" executions becomes those in $\mathcal{T}(\sigma)$ and ``correct" ones those in $\mathcal{E}(\sigma)$. This means that
\[
(\mathcal{T}(\sigma) = \emptyset) \Leftrightarrow \sigma \in \wlp[\regr](\lnot Q),
\]
from which we derive
\(\lnot \underline{P} \Rightarrow \wlp[\regr](\lnot Q)\)
or, equivalently,
\[\lnot \wlp[\regr](\lnot Q) \Rightarrow \underline{P} .\]

\begin{example}
	We consider again the same program $\regr$ from Example~\ref{ex:bg:il-hl-comparison}:

	\begin{minted}{C}
x := nondet();
if (x is even) {
	if (y is odd) {
		z := 42;
	}
}
// assert(z != 42)
	\end{minted}

	\noindent
	and the correctness specification $\neg Q_{42} = (z\neq 42)$. We have that $\wlp[\mathsf{r42nd}](\lnot \lnot Q_{42}) = Q_{42}$, because if initially $z \neq 42$ then it is possible that $x$ is assigned an odd value and $z$ is not updated.
	Hence, a condition $P$ is implied by $\lnot \wlp[\regr](\lnot\lnot Q_{42}) = \lnot Q_{42}$ if and only if it is necessary, e.g., $(z\neq 42 \vee \text{odd}(y))$ is necessary but $(z > 42)$ is not.
\end{example}

The next bijection establishes the connection between NC and HL: a necessary precondition is just the negation of a sufficient precondition for the negated post. This was also observed using weakest (liberal) preconditions in \cite[Theorem~5.4]{ZK22}.

\begin{prop}[Bijection between NC and HL]\label{prop:sil:fw-inclusion-negation-bw}
	For any  $\regr\in \Reg$ and $P, Q \subseteq \Sigma$:
	\[
	\fwsem{\regr} P \subseteq Q \Leftrightarrow \bwsem{\regr} (\lnot Q) \subseteq \lnot P \text{.}
	\]
\end{prop}

\subsubsection{SIL and IL}
Proposition~\ref{prop:sil:fw-inclusion-negation-bw} highlights an isomorphism between (HL) and (NC). This naturally sparks the question if there exists a similar connections between (IL) and (SIL), but the next example shows this is not the case.

\begin{example}\label{ex:sil:il-sil-incomparable}
	Since IL and SIL enjoy different consequence rules, neither of the two can imply the other with the same $P$ and $Q$. For negated $P$ and $Q$, consider the program
	\[
	\mathsf{r1} \eqdef x := 1
	\]
	and the two sets of states $P_{\geq 0} \eqdef (x \geq 0)$ and $Q_{1} \eqdef (x = 1)$.
	Both the SIL triple $\siltriple{P_{\geq 0}}{\mathsf{r1}}{Q_{1}}$ and the IL triple $\iltriple{P_{\geq 0}}{\mathsf{r1}}{Q_{1}}$ are valid. However, neither $\iltriple{\lnot P_{\geq 0}}{\mathsf{r1}}{\lnot Q_{1}}$ nor $\siltriple{\lnot P_{\geq 0}}{\mathsf{r1}}{\lnot Q_{1}}$ are valid. So neither (IL) implies negated (SIL) nor the other way around.
\end{example}

To gain some insights on why (SIL) and (IL) are not equivalent, we introduce the following concepts.

\begin{definition}
	Given a regular command $\regr$, we define the set of states that only diverges $D_{\regr}$ and the set of unreachable states $U_{\regr}$:
	\[
	D_{\regr} \eqdef \{ \sigma \mid \fwsem{\regr}\sigma = \emptyset \}
	\qquad
	U_{\regr} \eqdef \{ \sigma' \mid \sigma' \not\in\fwsem{\regr} \Sigma \} = \{ \sigma' \mid \bwsem{\regr}\sigma' = \emptyset \}.
	\]
\end{definition}

In a sense, $U_{\regr}$ is the set of states which ``diverge" going backward. In fact, if we consider $\bwsem{\regr}$ instead of $\fwsem{\regr}$, the roles of $D$ and $U$ are swapped.

\begin{lemma}\label{lmm:sil:CC-1-monotone}
	For any regular command $\regr \in \Reg$ and sets of states $P, Q \subseteq \Sigma$ it holds:
	\begin{enumerate}
		\item\label{lmm:sil:CC-1-monotone:1} $\bwsem{\regr} \fwsem{\regr} P \supseteq P \setminus D_{\regr}$;
		\item\label{lmm:sil:CC-1-monotone:2} $\fwsem{\regr} \bwsem{\regr} Q \supseteq Q \setminus U_{\regr}$.
	\end{enumerate}
\end{lemma}

This lemma highlights the asymmetry between over and under-approximation: the composition of a function with its inverse is increasing (but for non-terminating states).
This explains why (HL) and (NC) are related while (IL) and (SIL) are not: via over-approximation, $P \setminus D_{\regr} \subseteq \bwsem{\regr} \fwsem{\regr} P$ can be further exploited if we know $\fwsem{\regr} P \subseteq Q$ via (HL), but it cannot when $\fwsem{\regr} P \supseteq Q$ via (IL).

Lastly, while IL and SIL are not directly comparable, the preprint~\cite{RVO24} introduces a forward-oriented proof system with a core set of rules that are sound for both IL and SIL, therefore proving only triples that are valid for both. It also becomes complete for IL, resp. SIL, when augmented with the corresponding consequence rule.

\subsubsection{SIL and HL}
In general, HL and SIL have different goals, but they coincide whenever the program $\regr$ is deterministic and terminates for every input. This is formally captured by:

\begin{prop}\label{prop:sil:sil-hl-deterministic-terminating}
	For any $\regr\in \Reg$ and $P, Q \subseteq \Sigma$:
	\begin{itemize}
		\item if $\regr$ is deterministic, $\bwsem{\regr} Q \supseteq P \Rightarrow \fwsem{\regr} P \subseteq Q$
		\item if $\regr$ is terminating, $\fwsem{\regr} P \subseteq Q \Rightarrow \bwsem{\regr} Q \supseteq P$
	\end{itemize}
\end{prop}

%\subsection{Features Comparison}
%\label{sec:duality}

%A rule-by-rule comparison emphasizes the similarities and differences among logics (see Figure~\ref{fig:HLvsILvsSIL}, in Appendix for reviewers' convenience).
%%We distinguished the two main axis in Figure~\ref{fig:square-full} as over/under-approximation and forward/backward.
%The reference semantics is evident from rules $\mathsf{atom}$: HL and IL are forward oriented, and SIL is backward oriented.
%%This is also confirmed by the row for rules $\mathsf{iter}$ when comparing IL with SIL.
%The rule \hlrule{iter} of HL is based on any invariant, not necessarily the minimal one, so HL relies on over-approximation.
%Conversely, the rules $\mathsf{iter0}$ for SIL and IL (called \emph{iterate zero} in \cite{DBLP:journals/pacmpl/OHearn20}) under-approximates the Kleene star with zero iterations.
%The consequence rules follow the diagonals of Figure~\ref{fig:square-full}: SIL and HL can strengthen the pre and weaken the post, while IL and NC can do the opposite.

%\subsubsection*{Inference rules.}
%Let us compare the rules of SIL, HL and IL, so to emphasize the similarities and differences among them (for reviewers' convenience, all rules are collected in Figure~\ref{fig:HLvsILvsSIL}).
%%We distinguished the two main axis in Figure~\ref{fig:square-full} as over/under-approximation and forward/backward.
%The $\mathsf{atom}$ and $\mathsf{iter}$ rules show that HL and IL exploit the forward semantics, and SIL the backward one.
%%This is also confirmed by the row for rules $\mathsf{iter}$ when comparing IL with SIL.
%Furthermore, the rule \horule{iter} of HL says that any invariant is acceptable, not necessarily the minimal one, so that HL relies on over-approximation.
%This is confirmed by the rows for $\mathsf{cons}$ and $\mathsf{empty}$, where on the contrary IL and SIL are shown to rely on under-approximation.
%The consequence rule is the key rule of all the logics, because it allows to generalize a proof by weakening/strengthening the two conditions $P$ and $Q$ involved. The direction of rules \lrule{cons} of SIL and \horule{cons} of HL is the same and it is exactly the opposite direction of rule \irule{cons} of IL and NC, which coincide. So the different consequence rules follow the diagonals of Figure~\ref{fig:square-full}.
%The row for rules $\mathsf{seq}$ and $\mathsf{disj}$ show that in all cases triples can be composed sequentially and additively.
%Rules $\mathsf{iter0}$, $\mathsf{unroll}$ and $\mathsf{unroll\mbox{-}split}$ are a prerogative of under-approximation: they are the same for SIL and IL, but they are unsound for HL.

\subsection{Weakest/Strongest Conditions}
Depending on the way in which program analysis is conducted, it can be interesting to derive either the most general or most specific hypotheses for the given property.
For instance, given a correctness specification $Q$, one is typically interested in finding the minimal constraint on the input that guarantees program correctness.
Conversely, to infer necessary conditions we can be interested in devising the strongest hypotheses under which some correct run is possible.
Therefore, we exploit Figure~\ref{fig:sil:taxonomy} to investigate the existence of weakest/strongest conditions.

The concrete semantics is trivially a strongest (HL and NC) or weakest (IL and SIL) condition for the ``target'' property ($P$ computing backward and $Q$ forward).
However, it turns out that having a best condition on the ``source'' property is a prerogative of over-approximation, i.e., that over and under-approximation are not fully dual theories.

\begin{prop}\label{prop:sil:best-condition-source}
	For any regular command $\regr\in\Reg$:
	\begin{itemize}
		\item given $Q$, there exists a weakest $P$ such that $\fwsem{\regr} P \subseteq Q$ (HL);
		\item given $P$, there exists a weakest $Q$ such that $\bwsem{\regr} Q \subseteq P$ (NC);
		\item for some $Q$, there is no strongest $P$ such that $\fwsem{\regr} P \supseteq Q$ (IL);
		\item for some $P$, there is no strongest $Q$ such that $\bwsem{\regr} Q \supseteq P$ (SIL).
	\end{itemize}
\end{prop}

The reason why strongest conditions may not exist for IL and SIL is that collecting semantics (both forward and backward) are additive but not co-additive. In other words, rule \hlrule{disj} is sound for all triples, while a dual rule for conjunction such as
\[
\infer[\hlrule{conj}]
{\hltriple{P_1 \cap P_2}{\regr}{Q_1 \cap Q_2}}
{\hltriple{P_1}{\regr}{Q_1} & \hltriple{P_2}{\regr}{Q_2} }
\]
is valid for HL and NC but neither for IL nor SIL.
Since left adjoints are additive while right adjoints are co-additive~\cite{DP02}, this observation readily yields the existence of weakest conditions for over-approximation (i.e., weakest pre for HL and weakest post for NC) because these weakest conditions are right adjoints of the reference semantics. Conversely, strongest pre/post for IL/SIL cannot exists because they would be left adjoints of the reference semantics, which cannot be right adjoints because they are not co-additive.

For instance, given two HL preconditions $P_1$ and $P_2$ for the same post $Q$ (i.e., $\hltriple{P_1}{\regr}{Q}$ and $\hltriple{P_2}{\regr}{Q}$) also their union is a pre for $Q$, i.e., $\hltriple{P_1 \cup P_2}{\regr}{Q}$ using \hlrule{disj}. However, given two IL triples $\iltriple{P_1}{\regr}{Q}$ and $\iltriple{P_2}{\regr}{Q}$, in general $\fwsem{\regr} (P_1 \cap P_2) \nsupseteq Q$ and $\iltriple{P_1 \cap P_2}{\regr}{Q}$ is not valid, as shown in the following example.

\begin{example}\label{ex:sil:il-no-strongest-pre}
	Consider the program $\mathsf{r1} \eqdef x := 1$ of Example~\ref{ex:sil:il-sil-incomparable}.
	We can prove the two IL triples $\iltriple{x = 0}{\mathsf{r1}}{x = 1}$ and $\iltriple{x = 10}{\mathsf{r1}}{x = 1}$, but their intersection is $\iltriple{\emptyset}{\mathsf{r1}}{x = 1}$, which is not a valid IL triple.

	For SIL, consider the program $\mathsf{rnd} \eqdef \code{x := nondet()}$. For precondition $P_1 \eqdef (x = 1)$ we can prove both $\siltriple{P_1}{\mathsf{rnd}}{x = 0}$ and $\siltriple{P_1}{\mathsf{rnd}}{x = 10}$, that are incomparable, and again are both minimal because $\emptyset$ is not a valid postcondition.
\end{example}

\subsection{Termination and Reachability}
Termination and reachability are two sides of the same coin when switching from forward to backward semantics, and over and under-approximation behave differently with respect to these notions.

For HL we can only distinguish a precondition which always causes divergence: if $\hltriple{P}{\regr}{\emptyset}$, all states in the precondition $P$ will always diverge. However, if just one state in $P$ has one terminating computation, its final state must be in $Q\neq \emptyset$, so we cannot say whether states in $P$ diverge or not. Moreover, because of the over-approximation, a non empty $Q$ does not mean there truly are finite executions, as those may be introduced by the approximation.
Dually, NC cannot say much about reachability of $Q$ unless $P$ is empty, in which case $Q$ is unreachable.

On the contrary, under-approximation offers much stronger guarantees on termination/reachability. Any IL triple $\iltriple{P}{\regr}{Q}$ ensures that all states in $Q$ are reachable (in particular, from states in $P$). Dually, a SIL triple $\siltriple{P}{\regr}{Q}$ means that all states in $P$ have a convergent computation that ends in some state in $Q$. This observation motivates the design of a forward iteration rule in IL (resp. backward in SIL): a backward (resp. forward) rule would need to prove reachability of all points in the post (resp. pre). Instead, the forward rule of IL (resp. backward rule of SIL) ensures reachability (resp. termination) by construction, as it builds $Q$ (resp. $P$) only with points known to be reachable (resp. terminating).

\section{Separation Sufficient Incorrectness Logic}
We instantiate SIL to handle pointers and dynamic memory allocation, introducing Separation SIL. The goal of Separation SIL is to identify the causes of memory errors: it takes the backward under-approximation principles of SIL and combines it with the ability to deal with pointers from Separation Logic (SL)~\cite{Reynolds02,ORY01}

\paragraph*{Heap Regular Commands}
We denote by $\Regh$ the set of heap regular commands, obtained by plugging the following definition of heap atomic commands in~\eqref{eq:bg:regr-def} (in \textcolor{ACMBlue}{blue} new primitives):
\begin{align*}
	\Cmdh \ni \regc ::= \; & \code{skip} \mid \code{x := a} \mid \code{b?} \mid
	\textcolor{ACMBlue}{\code{x := alloc()} \mid \code{free(x)} \mid \code{x := [y]} \mid \code{[x] := y}}
\end{align*}
where we assume that \code{x} and \code{y} are syntactically distinct variables.
The command \code{x := alloc()} allocates a new memory location containing a nondeterministic value, \code{free(x)} deallocates memory, and \code{[$\cdot$]} dereferences a variable.
The syntax only allows to allocate, free and dereference single variables. To use a value from the heap in an arithmetic $\code{a} \in \AExp$ or Boolean expressions $\code{b} \in \BExp$, it must be loaded in a variable beforehand.

Given a heap command $\regr \in \Regh$, we let $\fv(\regr) \subseteq \Var$ be its set of free variables and $\modified(\regr) \subseteq \Var$ be the set of variables modified by $\regr$. The definition is standard (see Appendix, Definition~\ref{def:ssil-mod-regh}), but we remark that \code{free(x)} and \code{[x] := y} do not modify \code{x}: they only modify the value \emph{pointed by} \code{x}, not the actual value of \code{x} (the memory address itself).

Given a heap command $\regr \in \Regh$, we let $\fv(\regr) \subseteq \Var$ be the set of (free) variables appearing in $\regr$. We define the set $\modified(\regr) \subseteq \Var$ of variables modified by $\regr$ inductively by
\begin{align*}
	 & \modified(\code{skip}) = \emptyset \qquad                                        &  & \modified(\code{x := a}) = \{ \code{x} \}                                \\
	 & \modified(\code{b?}) = \emptyset \qquad                                          &  & \modified(\code{x := alloc()}) = \{ \code{x} \}                          \\
	 & \modified(\code{free(x)}) = \emptyset \qquad                                     &  & \modified(\code{x := [y]}) = \{ \code{x} \}                              \\
	 & \modified(\code{[x] := y}) = \emptyset                                           &  & \modified(\regr_1; \regr_2) = \modified(\regr_1) \cup \modified(\regr_2) \\
	 & \modified(\regr_1 \regplus \regr_2) = \modified(\regr_1) \cup \modified(\regr_2) &  & \modified(\regr^{\kstar}) = \modified(\regr)
\end{align*}

Please note that \code{free(x)} and \code{[x] := y} do not modify \code{x}: this is because they only modify the value \emph{pointed by} \code{x}, not the actual value of \code{x} (the memory address itself).

\paragraph*{Assertion Language}
Our assertion language is derived from SL and Incorrectness Separation Logic (ISL)~\cite{RBDDOV20}:
\begin{align*}
	\Asl \ni p, q ::= & \; \false \mid \true \mid p \land q \mid p \lor q \mid \exists x . p \mid \code{a} \asymp \code{a} \mid \emp \mid x \mapsto \code{a} \mid x \dealloc \mid p \andsep q
\end{align*}
where $\asymp \in \{ =, \neq, \le, <, \dots \}$ replaces standard comparison operators, $x \in \Var$ is a generic variable and $\code{a} \in \AExp$ is an arithmetic expression. The first six constructs describe a fragment of first-order logic, called coherent logic~\cite{BC05}. The last four describe heaps.
$\emp$ denotes an empty heap, $x \mapsto a$ represents an heap with a single memory cell pointed by $x$ and whose content is $a$, $x \dealloc$ describes that $x$ points to a previously deallocated memory cell.
The separating conjunction $p \andsep q$ is a key feature of Separation Logics and describes an heap which can be divided in two disjoint sub-heaps, one satisfying $p$ and the other $q$.
We let $x \mapsto - \eqdef \exists v. x \mapsto v$ describe that $x$ is allocated without tracking its exact value.
Given a formula $p \in \Asl$, we call $\fv(p) \subseteq \Var$ the set of its free variables.

\subsection{Proof System}\label{sec:sil:sepsil-proof-system}

\begin{figure}[t]
	\centering
	\begin{framed}
		\hspace*{-0.6em}
		\(
		\begin{array}{cc}
			\infer[\silrule{skip}]
			{\siltriple{\emp}{\code{skip}}{\emp}}
			{}
			\;                           &
			\infer[\silrule{assign}]
			{\siltriple{q[a / x]}{\code{x := a}}{q}}
			{}
			\\[7.5pt]
			\infer[\silrule{assume}]
			{\siltriple{q \land b}{\code{b?}}{q}}
			{}
			\;                           &
			\infer[\silrule{alloc}]
			{\siltriple{\emp}{\code{x := alloc()}}{x \mapsto v}}
			{}
			\\[7.5pt]
			\infer[\silrule{free}]
			{\siltriple{x \mapsto -}{\code{free(x)}}{x \dealloc}}
			{}
			\;                           &
			\infer[\silrule{load}]
			{\siltriple{y \mapsto a \andsep q[a / x]}{\code{x := [y]}}{y \mapsto a \andsep q}}
			{x \notin \fv(a)}
			\\[7.5pt]
			\infer[\silrule{store}]
			{\siltriple{x \mapsto -}{\code{[x] := y}}{x \mapsto y}}
			{}
			\\[7.5pt]
			\hline\hline                 &                                                               \\[-2pt]
			\infer[\silrule{exists}]
			{\siltriple{\exists x. p}{\regr}{\exists x. q}}
			{\siltriple{p}{\regr}{q}     & x \notin \fv(\regr)}
			\;                           &
			\infer[\silrule{frame}]
			{\siltriple{p \andsep t}{\regr}{q \andsep t}}
			{\siltriple{p}{\regr}{q}     & \fv(t) \cap \modified(\regr) = \emptyset}
			\\[7.5pt]
			\hline\hline                 &                                                               \\[-2pt]
			\infer[\silrule{cons}]
			{\siltriple{p}{\regr}{q}}
			{p \Rightarrow p'            & \siltriple{p'}{\regr}{q'}                 & q' \Rightarrow q}
			\;                           &
			\infer[\silrule{seq}]
			{\siltriple{p}{\regr_1; \regr_2}{q}}
			{\siltriple{p}{\regr_1}{t}   & \siltriple{t}{\regr_2}{q}}
			\\[7.5pt]
			\infer[\silrule{choice}]
			{\siltriple{p_1 \lor p_2}{\regr_1 \regplus \regr_2}{q}}
			{\siltriple{p_1}{\regr_1}{q} & \siltriple{p_2}{\regr_2}{q}}
			\;                           &
			\infer[\silrule{iter}]
			{\siltriple{\exists n. q(n)}{\regr^\kstar}{q(0)}}
			{\forall n \ge 0 \;\; \siltriple{q(n+1)}{\regr}{q(n)}}
			\\[7.5pt]
			\hline\hline                 &                                                               \\[-2pt]
			\infer[\silrule{empty}]
			{\siltriple{\false}{\regr}{q}}
			{}
			\;                           &
			\infer[\silrule{disj}]
			{\siltriple{p_1 \lor p_2}{\regr}{q_1 \lor q_2}}
			{\siltriple{p_1}{\regr}{q_1} & \siltriple{p_2}{\regr}{q_2}}
			\\[7.5pt]
			\infer[\silrule{iter0}]
			{\siltriple{q}{\regr^{\kstar}}{q}}
			{}
			\;                           &
			\infer[\silrule{unroll}]
			{\siltriple{p}{\regr^{\kstar}}{q}}
			{\siltriple{p}{\regr^{\kstar}; \regr}{q}}
		\end{array}
		\)
	\end{framed}
	\caption{Proof rules for Separation SIL. The first group replaces SIL rule \silrule{atom}, the second includes rules peculiar of SL, the third includes rule from SIL core set, and the fourth includes additional SIL rules.}
	\label{fig:sil:separation-sil}
\end{figure}

We present the rules of Separation SIL in Figure~\ref{fig:sil:separation-sil}. $q[a / x]$ denotes the usual capture-avoiding substitution of all free occurrences of $x$ in $q$ with the expression $a$.
Unlike ISL, we do not distinguish between correct and erroneous termination -- the goal of SIL is to trace back the causes of errors, not to follow the flow of a program after an error has occurred.

We split the rules in four groups.
The first group includes new rules of Separation SIL. The second one includes rules borrowed from SL.
The first group holds the rules for atomic commands $\regc \in \Cmdh$, i.e., all instances of the the SIL rule \silrule{atom}. The second has rules adapted from SL~\cite{Reynolds02,RBDDOV20}.
The third and fourth groups are the core and additional rules of SIL from Figure~\ref{fig:sil:sil-rules}.

All the rules in the first group are local: thanks to \silrule{frame}, they can specify only pre and post for the modified part of the heap.
Rule \silrule{skip} is trivial: whatever is true before and after the \code{skip} can be added with \silrule{frame}.
Rule \silrule{assign} is Hoare's backward assignment rule~\cite{Hoare69}.
Rule \silrule{assume} conjoins the assertion \code{b} to the postcondition: only states satisfying the Boolean guard have an execution.
Rule \silrule{alloc} allocates a new memory location for $x$. The premise is empty: if the previous content of $x$ is needed, $x = z$ can be introduced in the premise with \silrule{cons}.
Rule \silrule{free} requires $x$ to be allocated before freeing it.
Rule \silrule{load} is similar to \silrule{assign}, with the addition of the (disjoint) $y \mapsto a$ to make sure that $y$ is allocated.
Rule \silrule{store} requires that $x$ is allocated, and updates the value it points to.

The rule \silrule{exists} allows to ``hide" local variables.
The rule \silrule{frame} is typical of separation logics~\cite{Reynolds02}: it exploits the separating conjunction $\andsep$ to add a frame around a derivation, plugging the proof for a small portion of a program inside a larger heap.
In the third group, we instantiated the core set in Figure~\ref{fig:sil:sil-rules} for logical formulae, by replacing $\subseteq$ with $\Rightarrow$, $\cup$ with $\lor$ and $\emptyset$ with $\false$. The only notable difference is in rule \silrule{iter}, where Separation SIL uses a predicate $q(n)$ parametrized by the natural number $n \in \mathbb{N}$ and the precondition $\exists n. q(n)$ in the conclusion of the rule. This is a logical replacement for the infinite union used in SIL rule \silrule{iter}.
In the fourth group, we instantiated the additional rules of Figure~\ref{fig:sil:sil-rules}.

\subsection{Soundness}

\begin{figure}[t]
	\begin{subfigure}[t]{\linewidth}
		\centering
		\begin{align*}
			\edenot{\code{skip}} (s, h)         & \eqdef \{ (s, h) \}                                                                                    \\
			\edenot{\code{x := a}} (s, h)       & \eqdef \left\lbrace (s[x \mapsto \edenot{\code{a}} s], h) \right\rbrace                                \\
			\edenot{\code{b?}} (s, h)           & \eqdef \begin{cases*}
				                                             \left\lbrace (s, h) \right\rbrace & if $\edenot{\code{b}} s = \code{tt}$ \\
				                                             \emptyset                         & otherwise
			                                             \end{cases*}    \\
			\edenot{\code{x := alloc()}} (s, h) & \eqdef \left\lbrace (s[x \mapsto l], h[l \mapsto v]) \svert v \in \Val, \mathit{avail}(l)\right\rbrace \\
			\edenot{\code{free(x)}} (s, h)      & \eqdef
			\left\lbrace (s, h[s(x) \mapsto \delta]) \right\rbrace\quad \text{if}~h(s(x)) \in \Val                                                       \\
			\edenot{\code{x := [y]}} (s, h)     & \eqdef
			\left\lbrace (s[x \mapsto h(s(y))], h) \right\rbrace\quad \text{if}~h(s(y)) \in \Val                                                         \\
			\edenot{\code{[x] := y}} (s, h)     & \eqdef
			\left\lbrace (s, h[s(x) \mapsto s(y)]) \right\rbrace \quad \text{if}~h(s(x)) \in \Val
		\end{align*}
		\caption{Semantics of heap atomic commands, where we let $\mathit{avail}(l) \eqdef (l \notin \dom(h) \lor h(l) = \delta)$ and assume that $\edenot{\regc} (s, h)\eqdef \left\lbrace \errstate \right\rbrace$ unless differently stated.}
		\label{fig:sil:ssil-model-commands}
	\end{subfigure}
	\begin{subfigure}[t]{\linewidth}
		\vspace*{1ex}
		\centering
		\begin{align*}
			 & \asldenot{\false} \eqdef \emptyset                                                                                                          &  & \asldenot{p \land q} \eqdef \asldenot{p} \cap \asldenot{q}    \\
			 & \asldenot{\true} \eqdef \Sigma                                                                                                              &  & \asldenot{p \lor q} \eqdef \asldenot{p} \cup \asldenot{q}     \\
			 & \asldenot{a_1 \asymp a_2} \eqdef \{ (s, h) \svert \edenot{a_1} s \asymp \edenot{a_2} s \}                                                   &  & \asldenot{\emp} \eqdef \{ (s, []) \}                          \\
			 & \asldenot{x \mapsto a} \eqdef \{ (s, [s(x) \mapsto \edenot{a} s]) \}                                                                        &  & \asldenot{x \dealloc} \eqdef \{ (s, [s(x) \mapsto \delta]) \} \\
			 & \rlap{$\asldenot{\exists x. p} \eqdef \{ (s, h) \svert \exists v \in \Val \sdot (s[x \mapsto v], h) \in \asldenot{p} \}$}                                                                                      \\
			 & \rlap{$\asldenot{p \andsep q} \eqdef \{ (s, h_p \bullet h_q) \svert (s, h_p) \in \asldenot{p}, (s,h_q) \in \asldenot{q}, h_p \perp h_q \}$}
		\end{align*}
		\caption{Semantics of the assertion language.}
		\label{fig:sil:ssil-model-assertions}
	\end{subfigure}
	\caption{Ingredients to prove soundness of Separation SIL.}
\end{figure}

To prove soundness of Separation SIL, we give a semantic model for heap regular commands.
Fixed a finite set $\Var$ of variables and an infinite set $\Loc$ of memory locations, we define the set of values as $\Val \eqdef \setZ \uplus \Loc$ ($\uplus$ is disjoint union).
Stores $s \in \Stores$ are (total) functions $s: \Var \rightarrow \Val$; heaps $h \in \Heaps$ are partial functions $h: \Loc \rightharpoonup \Val \uplus \{ \delta \}$. If $h(l) = v \in \Val$, location $l$ is allocated and holds value $v$, if $l \notin \dom(h)$ then it is not allocated. The special value $\delta$ describes a deallocated memory location: if $h(l) = \delta$, that location was previously allocated and then deallocated.
As notation, we use $s[x \mapsto v]$ for function update, $[]$ for the empty heap and $[l \mapsto v]$ for the heap defined only on $l$ and associating value $v$ to it.
We say two heaps are disjoint, written $h_1 \perp h_2$, when $\dom(h_1) \cap \dom(h_2) = \emptyset$, and in that case we define the $\bullet$ operation as the merge of the two: $h_1 \bullet h_2$ coincides with $h_1$ on $\dom(h_1)$, with $h_2$ on $\dom(h_2)$ and it is undefined everywhere else.

Let $\Sigma = \Stores \times \Heaps$, and $\Sigma_e = \Sigma \uplus \{ \errstate \}$: states $\sigma \in \Sigma_e$ are either a pair store/heap or the error state \errstate{}.
The denotational semantics of atomic commands $\edenot{\cdot}: \Cmdh \rightarrow \wp(\Sigma_e) \rightarrow \wp(\Sigma_e)$ is in Figure~\ref{fig:sil:ssil-model-commands}. To simplify the presentation, we define it as $\edenot{\cdot}: \Cmdh \rightarrow \Sigma \rightarrow \wp(\Sigma_e)$, we let $\edenot{\regc} \errstate = \{ \errstate \}$, and we lift it to set of states by union.
Please note that evaluation of arithmetic $\code{a}$ and Boolean expressions $\code{b}$ only depends on the store since they cannot dereference variables.
We define the forward collecting semantics of heap commands $\fwsem{\cdot}: \Regh \rightarrow \wp(\Sigma_e) \rightarrow \wp(\Sigma_e)$ just as in Figure~\ref{fig:bg:regcom-sem} using the different semantics of atomic commands for $\regc \in \Cmdh$.

The semantics $\asldenot{\cdot}$ of a formula $p \in \Asl$ is a set of states in $\Sigma$. The full definition of $\asldenot{\cdot}$ is given in Figure~\ref{fig:sil:ssil-model-assertions}.

Just like SIL, we say a Separation SIL triple $\siltriple{p}{\regr}{q}$ is valid if $\bwsem{\regr} \asldenot{q} \supseteq \asldenot{p}$.
To prove soundness of Separation SIL, we rely on a stronger lemma, whose proof is by induction on the derivation tree.
Then, by taking $t = \emp$ and using $p \andsep \emp \equiv p$, we get the soundness of the proof system.

\begin{lemma}\label{lmm:sil:separation-sil-stronger-sound}
	Let $p, q, t \in \Asl$ and $\regr \in \Regh$. If $\vdash \siltriple{p}{\regr}{q}$ and $\fv(t) \cap \modified(\regr) = \emptyset$,
	\[
	\bwsem{\regr} \asldenot{q \andsep t} \supseteq \asldenot{p \andsep t}
	\]
\end{lemma}

\begin{corollary}[Separation SIL is sound]\label{th:sil:separation-sil-sound}
	Any provable Separation SIL triple is valid:
	\[
	\vdash \siltriple{p}{\regr}{q} \implies \vDash \siltriple{p}{\regr}{q}
	\]
\end{corollary}

\subsection{Separation SIL at Work}
We now discuss in full detail the use-after-lifetime example in~\cite{RBDDOV20} to show how Separation SIL can infer preconditions ensuring that a provided error can happen, and we comment on how SIL principles apply in the derivation.

\begin{figure}[t]
	\begin{align*}
		 & \silexact{p: v \mapsto z \andsep z \mapsto - \andsep \true}                                                                            \\
		 & \quad x := [v]                                                                                                                         \\
		 & \silexact{(\underline{v \mapsto z \andsep (x = z \lor x \dealloc)} \andsep z \mapsto - \andsep \true) \lor (x \dealloc \andsep \true)} \\
		 & \left(
		\begin{array}{l}
				\silexact{\true \andsep v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc)}               \\
				\quad y := [v];                                                                                        \\
				{\silexact{\true \andsep \underline{v \mapsto z \andsep y \mapsto - \andsep (x = y \lor x \dealloc)}}} \\
				\quad \text{free}(y);                                                                                  \\
				{\silexact{\true \andsep v \mapsto - \andsep \underline{y \dealloc} \andsep (x = y \lor x \dealloc)}}  \\
				\quad y := \text{alloc}();                                                                             \\
				{\silexact{x \dealloc \andsep v \mapsto - \andsep \underline{y \mapsto -} \andsep \true}}              \\
				\quad [v] := y                                                                                         \\
				{\silexact{x \dealloc \andsep \underline{v \mapsto y} \andsep \true}}
			\end{array}
		\right) \regplus \begin{array}{l}
			                 \silexact{x \dealloc \andsep \true} \\
			                 \quad \code{skip}                   \\
			                 \silexact{x \dealloc \andsep \true}
		                 \end{array}                                                                                      \\
		 & \silexact{q: x \dealloc \andsep \true}
	\end{align*}
	\caption{The proof sketch of $\siltriple{(v \mapsto z \andsep z \mapsto - \andsep \true)}{\mathsf{rclient}}{x \dealloc \andsep \true}$ (best read bottom-up). We write only the strengthened conditions obtained using \silrule{cons}, and \underline{underline} the post of the rule for the current atomic command. Everything else is shared between pre and post using \silrule{frame}.}
	\label{fig:sil:ssil-derivation}
\end{figure}

\begin{example}
	Consider the following program, used as example in~\cite{RBDDOV20}:

	\begin{center}
		\begin{minipage}{0.4\textwidth}
			\begin{minted}{C}
// rclient
x := *v;
push_back(v);
*x := 1;

\end{minted}
		\end{minipage}\quad
		\begin{minipage}{0.4\textwidth}
			\begin{minted}{C}
push_back(v) {
	if (nondet()) {
		free(*v);
		*v := alloc();
} }
\end{minted}
		\end{minipage}
	\end{center}

	We encode it as the regular command
	\begin{align*}
		\mathsf{rclient} & \eqdef x := [v];\ (\regr_{b} \regplus \code{skip})                \\
		\regr_{b}        & \eqdef y := [v];\ \text{free}(y);\ y := \text{alloc}();\ [v] := y
	\end{align*}

	Since our syntax does not include functions, we inline \code{push\_back}.
	We cannot free and allocate $*v$ directly, whence the auxiliary variable $y$. For simplicity,  we remove the last assignment \code{*x := 1} from $\mathsf{rclient}$: whenever the post $x \dealloc$ holds, an error occurs after $\mathsf{rclient}$.

	The proof sketch is in Figure~\ref{fig:sil:ssil-derivation}, where we annotate every step with the corresponding assertion.
	The derivation is best read bottom\hyp{}up: we start from the post and infer a suitable pre. For the sequential code in $\regr_b$, we start with a post, then strengthen it with rule \silrule{cons} to match the post of the rule for the corresponding atom, which may require adding some constraint on the shape of the heap.

	Particularly, we remark that to apply \silrule{free} for the line \code{free(y)}, $y$ must be deallocated. This can happen either if $y$ is a new name or if $y = x$, since $x$ is deallocated. This is captured by $y \dealloc \andsep (x = y \lor x \dealloc)$.

	We also observe that we use \silrule{cons} to drop the disjunct $(x \dealloc \andsep \true)$ before \code{x := [v]}: this is analogous to IL ability to drop disjuncts in the postcondition, but oriented backward.
\end{example}

In the example, we use as error postcondition $x \dealloc \andsep \true$. It is necessary to include $(\andsep\ \true)$ because, in final reachable states, $x$ is not the only variable allocated (there are also $v$ and $y$), so the final heap should talk about them as well. Adding $(\andsep\ \true)$ is a convenient way to focus only on the part of the heap that describes the error, that is $x \dealloc$, and just leave everything else unspecified.

For the same program, the ISL triple in~\cite{RBDDOV20} is
\[
\iltriple{v \mapsto z \andsep z \mapsto -}{\mathsf{rclient}}{v \mapsto y \andsep y \mapsto - \andsep x \dealloc} \text{.}
\]
This proves the existence of a faulty execution, but tells nothing about which input states actually lead to the error. On the other hand, the Separation SIL triple has a more succinct post capturing the error and provides a stronger guarantee: \emph{every} state in the precondition reaches the error, thus giving (many) actual witnesses for testing and debugging.

Lastly, we remark that, while in~\cite[Fig.~6]{ZDS23} a separation logic instance of Outcome Logic proves essentially the same triple, the deduction process is quite different from SIL.
OL reasoning is forward oriented, as witnessed by the implication that concludes the proof and by the triple for the $\code{skip}$ branch, whereas Separation SIL proof system naturally guides the backward inference of the precondition starting from the error postcondition (e.g., the pointer deallocated right before its dereferencing).

\subsection{Relative Completeness of Separation SIL}
Separation SIL is complete for all atomic commands but \code{alloc}, because it misses the ability to refer the specific memory location that gets allocated.
However, the naive solution to add $x = \alpha$ in the post of \silrule{alloc} would make the frame rule unsound: it would allow to prove, for instance, the invalid triple
\[
\siltriple{\emp \andsep \alpha \mapsto -}{\code{x := alloc()}}{(x \mapsto - \land x = \alpha) \andsep \alpha \mapsto -} \text{.}
\]
Just like ISL needs the deallocated assertion in the post~\cite[\S 3]{RBDDOV20}, Separation SIL needs a ``will be allocated'' assertion in the pre. To this end, we use the $\dealloc$ assertion, and change the semantic model to only allocate a memory location that is explicitly $\delta$. We formalize this by letting $\mathit{avail}(l) \eqdef h(l) = \delta$ in Figure~\ref{fig:sil:ssil-model-commands} and replacing the axiom \silrule{alloc} with

\[
\infer[\silrule{alloc}]
{\siltriple{\beta \dealloc{}}{\code{x := alloc()}}{x = \beta \land x \mapsto v}}
{}
\]

The proof system is still sound for this different semantics  model. Moreover, we can prove relative completeness~\cite[\S 4.3]{AO19} for loop-free programs:

\begin{theorem}[Relative completeness for loop-free programs]\label{th:sil:separation-sil-sequential-complete}
	Suppose to have an oracle to prove implications between formulas in $\Asl$. Let $\regr \in \Regh$ be a regular command without $\kstar$ and $p, q \in \Asl$ such that $\bwsem{\regr} \asldenot{q} \supseteq \asldenot{p}$. Then the triple $\siltriple{p}{\regr}{q}$ is provable.
\end{theorem}

The proof relies on an algorithmic rewriting of the postcondition that makes constraints on a single memory location explicit. This is given by the following lemma, whose proof is constructive (see the proof in Appendix~\ref{ch:app:sil}):

\begin{lemma}\label{lmm:sil:separation-assertion-rewrite}
	Let $q \in \Asl$ be a formula without $\exists$, and let $x'$ be a fresh variable. Then,
	\begin{enumerate}
		\item there exists a $\bar{q}$ such that $q \land (x \mapsto x' \andsep \true) \equiv x \mapsto x' \andsep \bar{q}$
		\item there exists a $\bar{q}$ such that $q \land (x \dealloc \andsep \true) \equiv x \dealloc \andsep \bar{q}$
	\end{enumerate}
\end{lemma}

Using this, for any atomic command $\regc \in \Cmdh$ we compute an assertion $t$ whose semantics is precisely the weakest possible pre $\bwsem{\regc} \asldenot{q}$, and prove the triple $\siltriple{t}{\regc}{q}$. Then, we extend this result to any program not containing $\kstar$, and conclude using the oracle and \silrule{cons} to prove the triple for any $p$ that implies $t$.
We conclude remarking that this is a result of completeness \emph{in the sense of Cook}~\cite{Cook78} since it means we can prove a triple whenever the pre for any loop is expressible.

\section{Conclusions}
\todo[inline]{Write this}
