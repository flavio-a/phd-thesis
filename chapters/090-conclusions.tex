% !TEX root = ../phd-thesis.tex

\chapter{Conclusions}\label{ch:conclusions}
Since proving \emph{incorrectenss} via under-approximation is a concept that recently attracted lots of attention, in this thesis we explored the possibility of combining over and under-approximation to improve the ability of both at proving a program correct or incorrect.

Surveying the literature, we found that most works in this direction (the embedding in KATs, $\LCLA$ and OL) are very recent, but PDR stood out as older. While it was probably not understood in these terms at the time, the success of PDR as a model checking technique shows the potential of this approach.

Given the impact of over-approximation based abstract interpretation in the established field of program analysis, our first question was whether under-approximation based abstract interpretation could have the same potential. It turns out that, for a wide class of analyses, the classical formulation of abstraction based on Galois connections is hard to turn effectively for under-approximation. Given this limitation, we then considered logical frameworks for under-approximation, and introduced a backward analogous to IL, which we dubbed SIL. Moreover, by comparing SIL, IL and two over-approximation logics (HL and NC) we further consolidated our understanding of the relations between over and under-approximation.

We apply the insight gained from the above studies in extending two known techniques.
First, we propose a new framework for $\LCLA$ that is able to prove intensional properties of programs by changing the domain in which (part of) the analysis is performed. We also present a way to circumvent the requirements of best abstraction, basically by performing a sanity check which guarantees soundness. Lastly, we turn $\LCLA$ over for backward analysis by using SIL instead of IL as the underlying program logic: the duality between the two proof systems streamlines the transfer of concepts.
Second, we introduce a new PDR-like algorithm which uses an adjoint (roughly corresponding to the backward semantics) to speed up the search for counterexamples. This algorithm allowed us to develop a theory of heuristics in which we can schematize, compare and have some reference points for devising new heuristics. We instantiate our algorithm for probabilistic systems: the experiments suggest that our approach is overall better than other PDR-like algorithms.

The main message of the thesis is that the interaction between over and under-approximation is far from trivial but shows great potential. Efficient exchange of meaningful information between over and under-approximation is sometimes elusive. In our opinion, this is partly due to the broken symmetry between over and under-approximation. However, if understood correctly, this information sharing can improve the combined search for correctness and incorrectness: under-approximation can guide the refinement process of the over-approximation, while over-approximation prevents under\hyp{}approximation from forgetting too much.

Our theoretical investigations have been complemented with experimental prototypes, that made possible to double check our examples, gain confidence in our methodologies and compare to the state of the art.

%In the future, we would like to deepen our understanding of the combination, possibly by studying the details of the interaction in approaches such as Outcome Logic, to be able to apply it in more and more settings.
Overall, the results in this thesis put new clarity in the relations and asymmetries between over and under-approximation which can serve as a basis for future investigations and applications. We outline here some possible research direction to pursue in the future.

\paragraph*{Future work.}
By analogy with PDR, where forward and backward analysis interact positively, we are thinking of a combination of IL and SIL. More precisely, we observe that the two logics share the structural rules (eg. sequential composition, finite loop unrolling). Therefore, given a proof tree in one of the two logics, the other is able to follow the same shape to prove a triple for the same program.
For instance, suppose to perform a forward analysis with IL which highlights some reachable error state. To pinpoint inputs leading to such errors, you could use SIL. Instead of following all possible program paths backward to find such sources, the IL proof tree already identifies program paths leading to those errors, that can thus be followed with SIL by mimicking the proof tree shape.

In our opinion, the ability of $\LCLA$ and CLCL to prove both correctness and incorrectness of a program at the same time shows potential for a useful tool. Indeed, our extensions allow them to be applied more easily in practice. Therefore, we are interested in exploring an implementation which combines domain refinement and abstract interpretation repair~\cite{BGGR22} for practical analyses.

Cousot's calculational design of program logics~\cite{Cousot24} opens the way to the possibility of comparing and combining over and under-approximation approaches from the abstract interpretation perspective. The most appealing aspect of this approach is the ability to automatically derive the combination, just like Cousot derives proof systems from a given composition of abstraction.

PDR presents an interesting framework which combines a forward search of a safe invariant with a backward search of a counterexample. We are considering other instantiations of this general idea, for instance via abstract interpretation for the over-approximation and abstract interpretation repair as the under. Specifically for program analysis, we are also considering a similar approach using HL for the forward over-approximation and SIL for the backward search for counterexamples, tailoring the algorithm to the stepwise program execution similarly to IC3 software model checking~\cite{LNNK20}.
