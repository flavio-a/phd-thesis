% !TEX root = ../phd-thesis.tex

\chapter{A comparison of program logics}\label{ch:sil}
In this chapter, we consider three known triple-based program logics, namely Hoare Logic (HL), Incorrectness Logic (IL) and Necessary Conditions (NC). We characterize their validity conditions in term of over or under-approximation of forward and backward semantics. First, this allows us to identify the absence of one combination, and thus to define a new program logic, called Sufficient Incorrectness Logic (SIL), for it. Second, this guides a thorough comparison of the four validity conditions, highlighting analogies and differences between over and under-approximation approaches.

The content of this chapter is based on~\cite{ABGL24}.

\section{Taxonomy}
\begin{figure}[t]
	\centering

	\begin{tabular}{@{\quad}c@{\quad}|@{\quad}rcr@{\quad}}
		       & \multicolumn{1}{c}{Forward}             &                                        & \multicolumn{1}{c}{Backward}                                 \\[3pt]
		\hline &                                         &                                        &                                                              \\[-5pt]
		Over   & HL: \quad $\fwsem{\regr} P \subseteq Q$ & $\xleftrightarrow{\qquad\simeq\qquad}$ & NC: \quad $\bwsem{\regr}Q \subseteq P$                       \\[5pt]
		Under  & IL: \quad $\fwsem{\regr}P \supseteq Q$  &                                        & \textcolor{ACMBlue}{SIL: \quad $\bwsem{\regr}Q \supseteq P$}
	\end{tabular}
	\caption{The taxonomy of validity conditions. Columns indicate if validity is based on forward or backward semantics and rows the verse of approximation. HL and NC are equivalent ($\simeq$). SIL is our new logic.}
	\label{fig:sil:taxonomy}
\end{figure}

As discussed in Sections~\ref{sec:bg:hl} and \ref{sec:bg:il}, the validity conditions of HL and IL are defined as over and under-approximation of the forward semantics $\fwsem{\cdot}$. However, other program logics cannot be naturally described in terms of $\fwsem{\cdot}$. To this end, we consider a backward semantics $\bwsem{\cdot}$ defined as the converse relation of the forward semantics,\footnote{Formally, if we consider a relation $\mathcal{R}$ between states defined as $\sigma \mathcal{R} \sigma'$ iff $\sigma' \in \fwsem{\regr} \sigma$, the backward semantics $\bwsem{\regr}$ defines the converse relation $\mathcal{R}^{-1}$} that is

\begin{equation}
	\bwsem{\regr} \sigma' \eqdef \{ \sigma \mid \sigma' \in \fwsem{\regr} \sigma \} \label{eq:sil:bwsem-definition}
\end{equation}

\noindent or, equivalently,

\begin{equation}
	\sigma \in \bwsem{\regr} \sigma' \iff \sigma' \in \fwsem{\regr} \sigma  \label{eq:sil:bwsem-sigma-sigma'}
\end{equation}

\noindent and we additively lift this definition to set of states by union.
Intuitively, the forward semantics $\fwsem{\regr} P$ denotes the set of all possible output states of $\regr$ when execution starts from a state in $P$ (and $\regr$ terminates).
Instead, the backward semantics $\bwsem{\regr} Q$ denotes the set of all input states that can lead to a state in $Q$.

The backward semantics can also be characterized compositionally, similarly to the forward one:

\begin{lemma}\label{lmm:sil:bwsem-calculus}
	For any regular commands $\regr,\regr_1,\regr_2\in \Reg$, the following equalities hold:
	\[
	\bwsem{\regr_1; \regr_2} = \bwsem{\regr_1} \circ \bwsem{\regr_2} \qquad\qquad
	\bwsem{\regr_1 \regplus \regr_2} = \bwsem{\regr_1} \cup \bwsem{\regr_2} \qquad\qquad
	\bwsem{{\regr^\kstar}} = \bigcup\limits_{n \ge 0} \bwsem{\regr}^n
	\]
\end{lemma}

Using $\bwsem{\cdot}$, we characterize NC with the validity condition $\bwsem{\regr} Q \subseteq P$.
To see why, assume $Q$ describes good final states. Then, $\bwsem{\regr} Q$ defines all states which can reach a good state. Since a precondition $\underline{P}$ is necessary for $Q$ if it contains every state which can reach a state in $Q$, $\underline{P}$ must contain at least all states in $\bwsem{\regr} Q$. More formally, for any initial state $\sigma \in \bwsem{\regr} Q$, there exist a $\sigma' \in \fwsem{\regr} \sigma$ such that $\sigma' \in Q$. This means that $\sigma$ has a trace in $\mathcal{T}(\sigma)$ (the one ending in $\sigma'$), so it must belong to any necessary precondition $\underline{P}$.

\begin{prop}[NC as backward over-approximation]\label{prop:sil:nc}
	Given a postcondition $Q$ for the program $\regr$, any possible necessary precondition $\underline{P}$ for $Q$ satisfies
	\[
	\bwsem{\regr} Q \subseteq \underline{P}
	\]
\end{prop}

Note that this is not a new understanding of NC (it was already hinted in the work that introduced them, and an analogous characterization appeared in~\cite[ยง6.3]{ZK22} in terms of weakest precondition), but the explicit use of the backward semantics in our contest enables a more streamlined comparison with other logics in Section~\ref{sec:sil:comparison}.

We organize the validity conditions of HL, IL and NC in the taxonomy in Figure~\ref{fig:sil:taxonomy}. We classify logics depending on (1) whether the condition is expressed in terms of forward or backward semantics and (2) whether it is an over or an under-approximation.
This naturally sparks the question on what does the backward under-approximation condition mean and whether a logic for it has been developed.

\paragraph{Backward under-approximation and Lisbon Triples}
At POPL'19 in Lisbon, D. Dreyer and R. Jung suggested that P. O'Hearn should look at bug-finding in terms of a logic for proving the presence of faults (as reported in~\cite{OHearn20,ZDS23}).
However, the proposed model of triples did not fit well with a key feature of Pulse, a bug-catching tool developed at Meta, namely its ability to drop the analysis of some program paths, for which IL provides a sound logical foundation instead.
The idea of such ``Lisbon'' triples is that \emph{for any initial state satisfying the pre, there exists some execution trace leading to a final state satisfying the post} and it can be dated back to Hoare's calculus of possible correctness~\cite{Hoare78}, even if no form of approximation was considered there.
Lisbon triples were then briefly discussed in~\cite[\S 5]{MOH21} and \cite[\S 3.2]{LRVBDO22} under the name \emph{backwards under-approximate triples}. They were also one of the motivations for OL~\cite{ZDS23}: OL recognized the importance of tracking the sources of errors and can encode Lisbon triples together with Hoare triples.
Backward under-approximation was also key for the development of a compositional non-termination analysis that has been integrated in Pulse~\cite{RVO24}, based on the observation that forward and backward under-approximation can be unified in a single logical framework by dropping the respective consequence rules.

Ideally, given an incorrectness specification, the goal of backward under-approximation would be to report to programmers all dangerous input states that lead to bugs.
However, all the above proposals are designed according to the forward semantics of programs and thus are best suited to infer postconditions starting from some given precondition. %: in general, their backward analysis may require the instantiation of their consequence rules with some ingenious guess.
To tackle this issue, we introduce Sufficient Incorrectness Logic (SIL) as a proof system for Lisbon triples with backward\hyp{}oriented rules.

Since in this chapter we deal with different kinds of program logics, a summary of the notation for the various triples is reported in Figure~\ref{fig:sil:notation-summary}.

\begin{figure}
	\centering
	\begin{tabular}{c|c@{\quad\enspace}c@{\quad\enspace}c@{\quad\enspace}c@{\quad\enspace}c}
		Logic                    &
		HL \cite{Hoare69}        &
		IL \cite{OHearn20}       &
		NC \cite{CCL11}          &
		OL \cite{ZDS23}          &
		SIL \cite{ABGL24}
		\\[2pt] \hline &&&&& \\[-10pt]
		Triples                  &
		$\hltriple{P}{\regr}{Q}$ &
		$\iltriple{P}{\regr}{Q}$ &
		$\nctriple{P}{\regr}{Q}$ &
		$\oltriple{P}{\regr}{Q}$ &
		$\siltriple{P}{\regr}{Q}$
	\end{tabular}
	\caption{Summary of the notation for different program logics}
	\label{fig:sil:notation-summary}
\end{figure}

\section{Sufficient Incorrectness Logic}\label{sec:sil:sil}

SIL is a backward\hyp{}oriented under\hyp{}approximation proof system for Lisbon triples that focuses on \emph{finding the sources of incorrectness rather than highlighting the presence of bugs}. Assuming the post $Q$ defines some class of errors, i.e., it is what we call an \emph{incorrectness specification}, a (valid) SIL triple $\siltriple{P}{\regr}{Q}$ means that ``\emph{all input states that satisfy $P$ have at least one execution of the program $\regr$ leading to a state that satisfies $Q$}''. For deterministic programs, SIL guarantees that a state satisfying the pre \emph{always} leads to an error. Instead, if $\regr$ is nondeterministic, SIL guarantees that there \emph{exists} an execution that leads to an error. Sufficient incorrectness preconditions are extremely valuable to programmers: by pointing out the sources of errors, they serve as a starting point to scope down debugging, fuzzing, and testing. Moreover, it is known that, contrary to IL and its extensions, backward under\hyp{}approximation can expose manifest errors \cite[ยง3.2]{LRVBDO22}: an error $Q$ is manifest iff the SIL triple $\siltriple{\true}{\regr}{Q}$ is valid. These are bugs that happen regardless of the context and it has been observed experimentally that are more likely to be fixed when reported~\cite[ยง5]{LRVBDO22}. Therefore, we study SIL to enhance program analysis frameworks with the ability to identify the source of incorrectness.

SIL goals include: (i)~defining a default deduction mechanism that starts from a specification of erroneous outcomes and traces the computation back to some initial states responsible for such errors; (ii)~exhibiting a minimal set of rules that are sound and complete for Lisbon triples; and (iii)~spelling out, a posteriori, a formalization of the backward analysis step performed by industrial grade analysis tools for security developed at Meta~\cite{DFLO19,MarianaTrench,Pysa}.
Those tools automatically find more than $50$\% of the security bugs in the Meta family of apps and many severe bugs~\cite[Fig.~5]{DFLO19}.

Roughly, the SIL triple
\[
\siltriple{P}{\regr}{Q}
\]
requires that all states in $P$ have at least one execution leading to a state in $Q$. More formally, for all $\sigma \in P$ there must exist a state $\sigma' \in Q$ such that $\sigma' \in \fwsem{\regr} \sigma$. Particularly, in the presence of nondeterminism states in $P$ are required to have one execution leading to $Q$, not necessarily all of them. Motivated by Figure~\ref{fig:sil:taxonomy}, we choose the validity condition
\[
\bwsem{\regr} Q \supseteq P. \tag{SIL}
\]
However, the two definition are equivalent:

\begin{prop}[Characterization of SIL validity]\label{prop:sil:sil-validity-characterization}
	For any $\regr \in \Reg$, $P, Q \subseteq \Sigma$
	\[
	\bwsem{\regr} Q \supseteq P \iff \forall \sigma \in P \sdot \exists \sigma' \in Q \sdot \sigma' \in \fwsem{\regr} \sigma
	\]
\end{prop}

A convenient way to exploit SIL is to assume that the analysis takes as input the incorrectness specification $Q$, i.e., the set of erroneous final states. Then, any valid SIL triple $\siltriple{P}{\regr}{Q}$ yields a precondition which surely captures erroneous executions. In this sense, $P$ gives a sufficient condition for incorrectness and motivates the name of SIL. This is dual to the interpretation of IL where, for a given precondition $P$, any IL triple $\iltriple{P}{\regr}{Q}$ yields a set $Q$ of final states which are for sure reachable, so that any error state in $Q$ is a true bug reachable from some input in $P$.

\subsection{Proof system}\label{sec:sil:sil-rules}

\begin{figure*}[t]
	\centering
	\begin{framed}
		\(
		\begin{array}{cc}
			\infer[\silrule{atom}]
			{\siltriple{\bwsem{\regc}Q}{\regc}{Q}}
			{}
			\quad                        &
			\infer[\silrule{cons}]
			{\siltriple{P}{\regr}{Q}}
			{P \subseteq P'              & \siltriple{P'}{\regr}{Q'}    & Q' \subseteq Q}
			\\[7.5pt]
			\infer[\silrule{seq}]
			{\siltriple{P}{\regr_1;\regr_2}{Q}}
			{\siltriple{P}{\regr_1}{R}   & \siltriple{R}{\regr_2}{Q}}
			\qquad                       &
			\infer[\silrule{choice}]
			{\siltriple{P_1 \cup P_2}{\regr_1 \regplus \regr_2}{Q}}
			{\siltriple{P_1}{\regr_1}{Q} & \siltriple{P_2}{\regr_2}{Q}}
			\\[7.5pt]
			\infer[\silrule{iter}]
			{\siltriple{\bigcup\limits_{n \ge 0} Q_n}{\regr^\kstar}{Q_0}}
			{\forall n \ge 0 \sdot \siltriple{Q_{n+1}}{\regr}{Q_n}}
		\end{array}
		\)\\
		\vspace{0.3em}
		\hrulefill \\
		\vspace{-2.5ex}\hrulefill
		\vspace{-0.2em}
		\begin{center}
			\small Additional rules
		\end{center}
		\(
		\begin{array}{cc}
			\infer[\silrule{empty}]
			{\siltriple{\emptyset}{\regr}{Q}}
			{}
			\qquad                       &
			\infer[\silrule{iter0}]
			{\siltriple{Q}{\regr^\kstar}{Q}}
			{}
			\\[7.5pt]
			\infer[\silrule{unroll}]
			{\siltriple{P}{\regr^\kstar}{Q}}
			{\siltriple{P}{\regr^\kstar; \regr}{Q}}
			\qquad                       &
			\infer[\silrule{disj}]
			{\siltriple{P_1 \cup P_2}{\regr}{Q_1 \cup Q_2}}
			{\siltriple{P_1}{\regr}{Q_1} & \siltriple{P_2}{\regr}{Q_2} }
		\end{array}
		\)
	\end{framed}
	\caption{Sufficient Incorrectness Logic}\label{fig:sil:sil-rules}
\end{figure*}

The inference rules for SIL are in Figure~\ref{fig:sil:sil-rules}. The top five rules form a minimal, sound and complete proof system. The additional rules are other valid rules that can ease program analysis and are discussed in Section~\ref{sec:sil:sil-rules-additional}.
Note that all the rules can be applied to an arbitrary post $Q$ to infer a corresponding pre, in the same way as all the rules of IL can be applied to an arbitrary pre $P$ to infer a corresponding post. This is a key feature of SIL proof system, which facilitates backward reasoning.

Atomic commands are handled by \silrule{atom}, which exploits the backward semantics and summarizes cases for \code{skip}, assignments and Boolean guards. In Section~\ref{sec:sil:rules-comparison} we discuss further the rule for assignment when pre and postconditions are formulae instead of sets of states.
The consequence rule allows to generalize a proof by weakening/strengthening the two conditions $P$ and $Q$ involved. It can readily be derived from the validity condition (SIL). Moreover, \silrule{cons} allows SIL to drop disjuncts in the pre, just as \ilrule{cons} allows IL do it in the post. This feature is crucial in both SIL and IL to increase scalability of tools.
Rule \silrule{seq} is standard: SIL triples are composed sequentially just like in all other logics.
Rule \silrule{choice} states that if all states in $P_1$ (resp. $P_2$) have an execution of $\regr_1$ (resp. $\regr_2$) ending in $Q$, they also have an execution of $\regr_1 \regplus \regr_2$ ending in $Q$ since the semantics of $\regr_1 \regplus \regr_2$ is a superset of that of $\regr_1$ (resp. $\regr_2$), cf. Figure~\ref{fig:bg:regcom-sem}. This rule is also reminiscent of the equation for conditionals in the calculus of possible correctness \cite{Hoare78}.
For iteration, for each $n \ge 0$ we find inductively the precondition $Q_n$ of executing $\regr$ exactly $n$ times. The precondition of the whole $\regr^{\kstar}$ is then the union of all the $Q_n$, as formalized by rule \silrule{iter}, which first appeared in \cite[ยง5]{MOH21}.

The SIL proof system is both correct and complete. Correctness can be proved by induction on the derivation tree of a triple. Intuitively, if the premises of a rule are valid, then its consequence is valid as well, as we briefly observed in above. To prove completeness, we rely on the fact that rules other than \silrule{cons} are exact, that is, if their premises satisfy the equality $\bwsem{\regr} Q = P$, their conclusion does as well. Using this, we prove the triple $\siltriple{\bwsem{\regr}Q}{\regr}{Q}$ for any $\regr$ and $Q$. We conclude using \silrule{cons} to get a proof of $\siltriple{P}{\regr}{Q}$ for any $P \subseteq \bwsem{\regr}Q$.

\begin{theorem}[SIL is sound and complete]\label{thm:sil:sil-sound-complete}
	A SIL triple is provable iff it is valid:
	\[
	\vdash\siltriple{P}{\regr}{Q} \iff \vDash\siltriple{P}{\regr}{Q}
	\]
\end{theorem}

\subsection{Additional rules for program analysis}\label{sec:sil:sil-rules-additional}
The topmost set of five rules in Figure~\ref{fig:sil:sil-rules} is deliberately minimal: if we remove any rule it is no longer complete. However, there are other valid rules, not derivable from those five, that can be useful in practice. Some of them are at the bottom of Figure~\ref{fig:sil:sil-rules}.

Rule \silrule{empty} is used to drop paths backward, just like IL can drop them forward (an analogous axiom $\iltriple{P}{\regr}{\emptyset}$ is valid for IL). Particularly, this allows to ignore one of the branches of \silrule{choice}, or to stop the backward iteration of \silrule{iter} without covering all the iterations. An example of such an application is the derived rule \silrule{iter0}, which corresponds to not entering the iteration at all. It can be derived from rules \silrule{iter} and \silrule{empty} by taking $Q_0 = Q$ and $Q_n = \emptyset$ for $n \ge 1$. It subsumes HL's rule \hlrule{iter}, which is based on loop invariants: those are a correct but not complete reasoning tool for under\hyp{}approximation~\cite{OHearn20}.
Rule \silrule{unroll} allows to unroll a loop once. Subsequent applications of this rule allow to simulate (backward) a finite number of iterations, and then rule \silrule{iter0} can be used to ignore the remaining ones. This is on par with IL ability to unroll a loop a finite number of times to find some post, for which analogous rules are valid~\cite{OHearn20,MOH21}.
Rule \silrule{disj} allows to split the analysis and join the results, just like HL and IL. However, while a corresponding rule \hlrule{conj} which perform intersection is sound for HL, it is unsound for both IL and SIL. We discuss this point further in Section~\ref{sec:sil:extremal-conditions}.

All four these additional rules are sound (it can be proved by induction):
\begin{prop}\label{prop:sil:sil-additional-soundness}
	The additional SIL rules at the bottom of Figure~\ref{fig:sil:sil-rules} are sound, that is, triples provable in SIL extended with those rules are valid.
\end{prop}

\begin{example}\label{ex:sil:derivation}
	Let us consider the program ``loop0'' from~\cite[\S 6.1]{OHearn20}:

	\begin{minted}{C}
x := 0;
n := nondet();
while(n > 0) {
    x := x + n;
    n := nondet();
}
// assert(x != 2000000)
	\end{minted}

	We can translate it in the syntax of regular commands by letting
	\begin{align*}
		\regr_w         & \eqdef \code{(n > 0)?; x := x + n; n := nondet()}                         \\
		\mathsf{rloop0} & \eqdef \code{x := 0; n := nondet(); }(\regr_w)^{\kstar}; \code{(n <= 0)?}
	\end{align*}
	Final error states are those in $Q_{2M} \eqdef (x = 2 000 000)$.

	\begin{figure}[t]
		\centering
		\footnotesize
		\[
		\infer[]
		{(*)}
		{
			\infer[\silrule{seq}]{\siltriple{T_{2M}}{\regr_w^{\kstar}; \code{(n <= 0)?}}{Q_{2M}}}{
				\infer[\silrule{unroll}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{R_{2M}}}{
					\infer[\silrule{seq}]{\siltriple{T_{2M}}{\regr_w^{\kstar}; \regr_w}{R_{2M}}}{
						\infer[\silrule{iter0}]{\siltriple{T_{2M}}{\regr_w^{\kstar}}{T_{2M}}}{}
						&
						\infer{\siltriple{T_{2M}}{\regr_w}{R_{2M}}}{\vdots}
					}
				}
				&
				\infer[\silrule{atom}]{\siltriple{R_{2M}}{\code{(n <= 0)?}}{Q_{2M}}}{}
			}
		}
		\]

		\[
		\infer[\silrule{seq}]
		{\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}}
		{
			\infer[\silrule{seq}]{\siltriple{\true}{\code{x := 0; n := nondet()}}{T_{2M}}}{
				\infer[\silrule{atom}]{\siltriple{\true}{\code{x := 0}}{x \le 2000000}}{}
				&
				\infer[\silrule{atom}]{\siltriple{x \le 2000000}{\code{n := nondet()}}{T_{2M}}}{}
			}
			&
			(*)
		}
		\]
		\caption{Derivation of the SIL triple $\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}$ for Example~\ref{ex:sil:derivation}.}
		\label{fig:sil:example-derivation}
	\end{figure}

	To prove a triple for $\mathsf{rloop0}$, we have to perform at least one iteration, and we do so using \silrule{unroll}.
	We let $R_{2M} \eqdef (x = 2000000 \land n \le 0)$ and $T_{2M} \eqdef (x + n = 2000000 \land n > 0)$. It is straightforward to prove $\siltriple{T_{2M}}{\regr_w}{R_{2M}}$ via \silrule{seq} and \silrule{atom}. Given this triple, we can unroll the loop once and prove the same triple for $\regr_w^{\kstar}$, as shown by the combination of \silrule{unroll}, \silrule{seq} and \silrule{iter0} at the top-left of Figure~\ref{fig:sil:example-derivation}. This is a property of under-approximation: a nondeterministic number of iterations can be under-approximated by a single iteration \cite[\S 6.1]{OHearn20}.
	With this triple for the loop, we can prove for the whole program the triple $\siltriple{\true}{\mathsf{rloop0}}{Q_{2M}}$ using \silrule{seq} and \silrule{atom}. The full derivation is in Figure~\ref{fig:sil:example-derivation}.

	Differently than IL, this triple highlights that any initial state can lead to an error: instead of reporting the presence of a true bug, we can prove that this is a manifest error and produce an initial state which causes the bug.
\end{example}

\section{Relations among logics}\label{sec:sil:comparison}
We first follow the two-dimensional scheme in Figure~\ref{fig:sil:taxonomy} to carry out a duality-driven comparison among the four validity conditions. Then, we realize that analogies and differences between them can be studied along other axes to obtain interesting insights among the relations between over/under-approximation, forward/backward analysis, reachability/divergence, and others.

We named columns of Figure~\ref{fig:sil:taxonomy} based on which semantics (forward or backward) they use. However, there is not a unique way of fixing the over and under-approximation axes. For instance, it is possible to take the consequence rules as the approximation axis, naming IL and NC as under-approximation because you can always substitute $Q$ for one of its under-approximations $Q' \subseteq Q$. However, we chose to denote approximation depending on the ``target'' set, that is, $Q$ for forward and $P$ for backward semantics, respectively. We motivate this choice because it classifies both IL and SIL as under-approximation and they share the ability to drop program paths (e.g., by finite unrolling of loops).

\subsection{Pairwise comparison}
We first carry out a comparison of the logics two by two. We skip the pair HL and IL since it was already discussed when IL was introduced in \cite{OHearn20}.

\subsubsection{NC and IL}
Sufficient preconditions are properties that imply Dijkstra's $\wlp$: $\overline{P}$ is sufficient for a postcondition $Q$ if and only if $\overline{P} \subseteq \wlp[\regr](Q)$, which in turn is equivalent to validity of the HL triple $\hltriple{\overline{P}}{\regr}{Q}$. Necessary and sufficient preconditions are dual, and so are IL and HL. Moreover, NC and IL enjoy the same consequence rule: both can strengthen the post and weaken the pre. This double duality suggests a relation between NC and IL. However, the following example shows this is not the case.

\begin{example}\label{ex:sil:nc-and-il}
	Consider the nondeterministic program $\regr 42$ from Example~\ref{ex:bg:il-hl-comparison}, where $Q_{42} \eqdef (z = 42)$. For brevity, we let $Q'_{42} \eqdef (Q_{42} \land \text{odd}(y) \land \text{even}(x))$.
	From that Example we know that $\iltriple{z = 11}{\regr 42}{Q'_{42}}$ is valid in IL. However, we observe that the NC triple $\nctriple{z = 11}{\regr 42}{Q'_{42}}$ is not valid because, e.g., the state $[y \mapsto 1, z \mapsto 10]$ has an execution leading to $Q'_{42}$ but doesn't satisfy $z = 11$.
	Moreover, take for instance $\underline{P} \eqdef \text{odd}(y)$, which makes the NC triple $\nctriple{\underline{P}}{\regr 42}{Q'_{42}}$ valid (in any state \emph{not} satisfying $\underline{P}$ $y$ is even, is not changed by $\regr 42$ and should be odd to satisfy $Q'_{42}$). Then it is clear that $(z = 11) \notimplies \underline{P}$. This shows that not only IL triples do not yield NC triples, but also that in general there are NC preconditions which are not implied by IL preconditions.

	Conversely, consider $\lnot Q_{42} = (z \neq 42)$. While the NC triple $\nctriple{\true}{\regr 42}{\lnot Q_{42}}$ is valid, the IL triple $\iltriple{\true}{\regr 42}{\lnot Q_{42}}$ is not: for instance, the final state $[x \mapsto 11, y \mapsto 11, z \mapsto 11]$ is not reachable from any initial state. It follows that the IL triple $\iltriple{P}{\regr 42}{\lnot Q_{42}}$ is not valid for any $P$.
\end{example}

Given $\vDash \nctriple{\underline{P}}{\regr}{Q}$ and $\vDash \iltriple{P}{\regr}{Q}$, there always are states satisfying both $P$ and $\underline{P}$, i.e., $P \cap \underline{P} \neq \emptyset$. However, in general neither $P \subseteq \underline{P}$ nor $\underline{P} \subseteq P$. The difference between NC and IL becomes apparent when we spell out their validity conditions using quantifiers:
\begin{align*}
	\forall \sigma' \in Q \sdot \forall \sigma\in \bwsem{\regr}\sigma' \sdot\sigma\in P
	\tag{NC$_{\text{FOL}}$} \\
	\forall \sigma' \in Q \sdot \exists \sigma\in \bwsem{\regr}\sigma' \sdot \sigma \in P
	\tag{\ref{eq:bg:il-fol}}
\end{align*}
Initial states are universally quantified in (NC$_{\text{FOL}}$)---\emph{all} initial states with a good run must satisfy the precondition---but they are existentially quantified in (IL$_{\text{FOL}}$). We also note that, when $\regr$ is reversible (i.e., $\fwsem{\regr}$ is injective) any valid IL triple is also a valid NC triple.

\subsubsection{NC and HL}
It turns out that NC is strongly connected to weakest liberal preconditions and thus to HL.
Let $Q$ be a correctness postcondition: a finite trace is in $\mathcal{T}(\sigma)$ if its final state satisfies $Q$ and in $\mathcal{E}(\sigma)$ otherwise. In general, a necessary precondition has no relationship with $\wlp[\regr](Q)$. However, if we consider $\lnot Q$ instead of $Q$, we observe that ``erroneous" executions becomes those in $\mathcal{T}(\sigma)$ and ``correct" ones those in $\mathcal{E}(\sigma)$.
This means that $\mathcal{T}(\sigma) = \emptyset$ iff $\sigma \in \wlp[\regr](\lnot Q)$, from which we derive $\lnot \underline{P} \subseteq \wlp[\regr](\lnot Q)$ or, equivalently, $\lnot \wlp[\regr](\lnot Q) \subseteq \underline{P}$.

\begin{example}
	Consider again program $\regr 42$ from Example~\ref{ex:bg:il-hl-comparison} and the correctness specification $\lnot Q_{42} = (z\neq 42)$. We have that $\wlp[\regr 42](\lnot \lnot Q_{42}) = Q_{42}$, because if initially $z \neq 42$ then it is possible that $x$ is assigned an odd value and $z$ is not updated.
	Hence, a condition $P$ is implied by $\lnot \wlp[\regr](\lnot\lnot Q_{42}) = \lnot Q_{42}$ if and only if it is necessary. For instance, $(z \neq 42 \lor \text{odd}(y))$ is necessary but $(z > 42)$ is not.
\end{example}

The next bijection establishes the connection between (NC) and (HL): a necessary precondition is just the negation of a sufficient precondition for the negated post. This was also observed using weakest (liberal) preconditions in \cite[Theorem~5.4]{ZK22}.

\begin{prop}[Bijection between NC and HL]\label{prop:sil:fw-inclusion-negation-bw}
	For any  $\regr\in \Reg$ and $P, Q \subseteq \Sigma$:
	\[
	\fwsem{\regr} P \subseteq Q \iff \bwsem{\regr} (\lnot Q) \subseteq \lnot P \text{.}
	\]
\end{prop}

\subsubsection{SIL and IL}
Proposition~\ref{prop:sil:fw-inclusion-negation-bw} highlights an isomorphism between (HL) and (NC). By duality, this naturally sparks the question whether a similar connections between (IL) and (SIL) exists. The next example shows this is not the case.

\begin{example}\label{ex:sil:il-sil-incomparable}
	Since IL and SIL enjoy different consequence rules, neither of the two can imply the other with the same $P$ and $Q$. If we take negation into account, consider the program $\regr 1 \eqdef \code{x := 1}$.
	Both the SIL triple $\siltriple{x \ge 0}{\regr 1}{x = 1}$ and the IL triple $\iltriple{x \ge 0}{\regr 1}{x = 1}$ are valid. However, neither $\iltriple{x < 0}{\regr 1}{x \neq 1}$ nor $\siltriple{x < 0}{\regr 1}{x \neq 1}$ are valid.
	So neither (IL) implies negated (SIL) nor the other way around.
\end{example}

To gain some insights on why (SIL) and (IL) are not equivalent, we introduce the following concepts.

\begin{definition}
	Given a regular command $\regr$, we define the set of states that only diverges $D_{\regr}$ and the set of unreachable states $U_{\regr}$:
	\[
	D_{\regr} \eqdef \{ \sigma \mid \fwsem{\regr}\sigma = \emptyset \}
	\qquad
	U_{\regr} \eqdef \{ \sigma' \mid \sigma' \not\in\fwsem{\regr} \Sigma \} = \{ \sigma' \mid \bwsem{\regr}\sigma' = \emptyset \}.
	\]
\end{definition}

These two definition are dual when we reverse the execution direction: if we consider $\bwsem{\regr}$ instead of $\fwsem{\regr}$, the roles of $D$ and $U$ are swapped. This means that, in a sense, $U_{\regr}$ is the set of states which ``diverge" going backward.

\begin{lemma}\label{lmm:sil:CC-1-monotone}
	For any regular command $\regr \in \Reg$ and sets of states $P, Q \subseteq \Sigma$ it holds:
	\[
	\bwsem{\regr} \fwsem{\regr} P \supseteq P \setminus D_{\regr} \qquad\qquad \fwsem{\regr} \bwsem{\regr} Q \supseteq Q \setminus U_{\regr} \text{.}
	\]
\end{lemma}

This lemma highlights the asymmetry between over and under-approximation: the composition of a function with its inverse is increasing (but for non-terminating states).
This explains why (HL) and (NC) are related while (IL) and (SIL) are not: for over-approximation, $P \setminus D_{\regr} \subseteq \bwsem{\regr} \fwsem{\regr} P$ can be further exploited if we know $\fwsem{\regr} P \subseteq Q$ via (HL), but it cannot when $\fwsem{\regr} P \supseteq Q$ via (IL).

Lastly, while IL and SIL are not directly comparable, the preprint~\cite{RVO24} introduces a forward-oriented proof system with a core set of rules that are sound for both IL and SIL, therefore proving only triples that are valid for both. It also becomes complete for IL, resp. SIL, when augmented with the corresponding consequence rule.

\subsubsection{SIL and HL}
In general, HL and SIL are different, but they coincide whenever the program $\regr$ is deterministic and terminates for every input.

\begin{prop}\label{prop:sil:sil-hl-deterministic-terminating}
	For any $\regr\in \Reg$ and $P, Q \subseteq \Sigma$:
	\begin{itemize}
		\item if $\regr$ is deterministic, $\bwsem{\regr} Q \supseteq P \implies \fwsem{\regr} P \subseteq Q$
		\item if $\regr$ is terminating, $\fwsem{\regr} P \subseteq Q \implies \bwsem{\regr} Q \supseteq P$
	\end{itemize}
\end{prop}

\begin{example}
	From Example~\ref{ex:bg:il-hl-comparison}, we know $\hltriple{\text{odd}(y)}{\regr 42}{Q_{42}}$ is a valid HL triple. Moreover, $\regr 42$ always terminates, so according to Proposition~\ref{prop:sil:sil-hl-deterministic-terminating} $\siltriple{\text{odd}(y)}{\regr 42}{Q_{42}}$ is valid. Indeed, whenever $y$ is odd in the initial state, $x$ can be assigned nondeterministically an even value so that execution enters the if statement and $z$ is assigned $42$.
\end{example}

\subsection{Inference rules}\label{sec:sil:rules-comparison}

\begin{figure}[t]
	\resizebox{\textwidth}{!}{
		\begin{tabular}{c|ccc}
			Rule   & SIL                                                                                                                          & HL                              & IL                    \\
			\hline &                                                                                                                              &                                 &                       \\
			$\mathsf{atom}$
			       & \infer[]{\siltriple{\bwsem{\regc}Q}{\regc}{Q}}{}
			       & \textcolor{ACMPurple}{\infer[]{\hltriple{P}{\regc}{\fwsem{\regc}P}}{}}
			       & \textcolor{ACMPurple}{\infer[]{\iltriple{P}{\regc}{\fwsem{\regc}P}}{}}
			\\[1em]
			$\mathsf{cons}$
			       & \quad\textcolor{ACMPurple}{\infer[]{\siltriple{P}{\regr}{Q}}{P \subseteq P'                                                  & \siltriple{P'}{\regr}{Q'}       & Q' \subseteq Q}}\quad
			       & \quad\textcolor{ACMPurple}{\infer[]{\hltriple{P}{\regr}{Q}}{P \subseteq P'                                                   & \hltriple{P'}{\regr}{Q'}        & Q' \subseteq Q}}\quad
			       & \quad\infer[]{\iltriple{P}{\regr}{Q}}{P \supseteq P'                                                                         & \iltriple{P'}{\regr}{Q'}        & Q' \supseteq Q}\quad
			\\[1em]
			$\mathsf{seq}$
			       & \textcolor{ACMPurple}{\infer[]{\siltriple{P}{\regr_1;\regr_2}{Q}}{\siltriple{P}{\regr_1}{R}                                  & \siltriple{R}{\regr_2}{Q}}}
			       & \textcolor{ACMPurple}{\infer[]{\hltriple{P}{\regr_1;\regr_2}{Q}}{\hltriple{P}{\regr_1}{R}                                    & \hltriple{R}{\regr_2}{Q}}}
			       & \textcolor{ACMPurple}{\infer[]{\iltriple{P}{\regr_1;\regr_2}{Q}}{\iltriple{P}{\regr_1}{R}                                    & \iltriple{R}{\regr_2}{Q}}}
			\\[1em]
			$\mathsf{choice}$
			       & \infer[]{\siltriple{P_1 \cup P_2}{\regr_1 \regplus \regr_2}{Q}}{\forall i \in \{ 1, 2 \}                                     & \siltriple{P_i}{\regr_i}{Q}}
			       & \infer[]{\hltriple{P}{\regr_1 \regplus \regr_2}{Q}}{\forall i \in \{ 1, 2 \}                                                 & \hltriple{P}{\regr_i}{Q}}
			       & \infer[]{\iltriple{P}{\regr_1 \regplus \regr_2}{Q_1 \cup Q_2}}{\forall i \in \{ 1, 2 \}                                      & \iltriple{P}{\regr_i}{Q_i}}
			\\[1em]
			$\mathsf{iter}$
			       & \infer[]{\siltriple{\bigcup\limits_{n \ge 0} Q_n}{\regr^\kstar}{Q_0}}{\forall n \ge 0 \sdot \siltriple{Q_{n+1}}{\regr}{Q_n}}
			       & \infer[]{\hltriple{P}{\regr^\kstar}{P}}{\hltriple{P}{\regr}{P}}
			       & \infer[]{\iltriple{P_0}{\regr^\kstar}{\bigcup\limits_{n \ge 0} P_n}}{\forall n \ge 0 \sdot \iltriple{P_n}{\regr}{P_{n+1}}}
			\\[1.5em]
			$\mathsf{empty}$
			       & \textcolor{ACMPurple}{\infer[]{\siltriple{\emptyset}{\regr}{Q}}{}}
			       & \textcolor{ACMPurple}{\infer[]{\hltriple{\emptyset}{\regr}{Q}}{}}
			       & \infer[]{\iltriple{P}{\regr}{\emptyset}}{}
			\\[1em]
			$\mathsf{disj}$
			       & \textcolor{ACMPurple}{\infer[]{\siltriple{P_1 \cup P_2}{\regr}{Q_1 \cup Q_2}}{\siltriple{P_1}{\regr}{Q_1}                    & \siltriple{P_2}{\regr}{Q_2} } }
			       & \textcolor{ACMPurple}{\infer[]{\hltriple{P_1 \cup P_2}{\regr}{Q_1 \cup Q_2}}{\hltriple{P_1}{\regr}{Q_1}                      & \hltriple{P_2}{\regr}{Q_2} } }
			       & \textcolor{ACMPurple}{\infer[]{\iltriple{P_1 \cup P_2}{\regr}{Q_1 \cup Q_2}}{\iltriple{P_1}{\regr}{Q_1}                      & \iltriple{P_2}{\regr}{Q_2} } }
			\\[1.5em]
			$\mathsf{iter0}$
			       & \textcolor{ACMPurple}{\infer[]{\siltriple{Q}{\regr^\kstar}{Q}}{}}
			       & unsound
			       & \textcolor{ACMPurple}{\infer[]{\iltriple{P}{\regr^\kstar}{P}}{}}
			\\[1em]
			$\mathsf{unroll}$
			       & \textcolor{ACMPurple}{\infer[]{\siltriple{P}{\regr^\kstar}{Q}}{\siltriple{P}{\regr^\kstar; \regr}{Q}}}
			       & unsound
			       & \textcolor{ACMPurple}{\infer[]{\iltriple{P}{\regr^\kstar}{Q}}{\iltriple{P}{\regr^\kstar; \regr}{Q}}}
			\\ [1em]
			$\mathsf{conj}$
			       & unsound
			       & \infer[]{\hltriple{P_1 \cap P_2}{\regr}{Q_1 \cap Q_2}}{\hltriple{P_1}{\regr}{Q_1}                                            & \hltriple{P_2}{\regr}{Q_2} }
			       & unsound
		\end{tabular}
	}
	\caption{Comparison of SIL, HL and IL rules. Identical rules are highlighted in \textcolor{ACMPurple}{purple}.}
	\label{fig:sil:rules-comparison}
\end{figure}

In Figure~\ref{fig:sil:rules-comparison} we compare the rules of SIL, HL and IL, so to emphasize the similarities and differences among them.
HL rule \hlrule{iter} says that any invariant is acceptable, not necessarily the minimal one, so that HL relies on over-approximation.
This is confirmed by the rows for $\mathsf{cons}$ and $\mathsf{empty}$, where on the contrary IL and SIL are shown to rely on under-approximation.
The consequence rule is the key rule of all the logics, because it allows to generalize a proof by weakening/strengthening the two conditions $P$ and $Q$ involved. The direction of rules \silrule{cons} of SIL and \hlrule{cons} of HL is the same and it is exactly the opposite direction of rule \ilrule{cons} of IL and NC, which coincide. So the different consequence rules follow the diagonals of Figure~\ref{fig:sil:taxonomy}.
The row for rules $\mathsf{seq}$ and $\mathsf{disj}$ show that in all cases triples can be composed sequentially and additively.
Rules $\mathsf{iter0}$ and $\mathsf{unroll}$ correspond to finite loop unrolling and are a prerogative of under-approximation: they are the same for SIL and IL, but they are unsound for HL.

The $\mathsf{atom}$ rule deserves a more in-depth discussion. The presented version using sets shows that HL and IL exploit the forward semantics, and SIL the backward one. However, if we instead use formulae as pre and postconditions, this rule must be instantiated for all atomic construct, particularly for assignments.
It is well known that there are two different, valid axioms for assignment in HL: Hoare's backward substitution~\cite{Hoare69} and Floyd's forward inference~\cite{Floyd67} (where $q[a / x]$ denotes the usual capture-avoiding substitution of all free occurrences of $x$ in $q$ with the expression $a$).
\[
\infer[\hlrule{Hoare}]
{\hltriple{q[a / x]}{\code{x := a}}{q}}
{}
\qquad
\infer[\hlrule{Floyd}]
{\hltriple{p}{\code{x := a}}{\exists x'. p[x'/x]\wedge x=a[x'/x]}}
{}
\]
While both axioms are valid in HL, only Floyd's forward axiom is valid in IL~\cite[\S 4]{OHearn20}, already showing a broken symmetry between over and under-approximation.
While our presentation of SIL rules uses sets of states, we use Hoare's backward substitution in Separation SIL (see Figure~\ref{fig:sil:separation-sil}): dually to the forward IL, the backward axiom is valid for SIL. Surprisingly, Floyd's forward axiom is valid in SIL as well: this shows that even for under-approximation, forward and backward semantics behave differently. This is possibly rooted in the properties of arithmetic expressions: they are defined for every input but not necessarily surjective. In the terminology of Lemma~\ref{lmm:sil:CC-1-monotone}, $D_{\code{x:=a}}$ is always empty but $U_{\code{x:=a}}$ may not be.

\subsection{Weakest/strongest conditions}\label{sec:sil:extremal-conditions}
Depending on the way in which program analysis is conducted, it can be interesting to derive either the most general or most specific hypotheses for the given property.
For instance, given a correctness specification $Q$, one is typically interested in finding the minimal constraint on the input that guarantees program correctness (this correspond to computing Dijkstra's \wlp{}).
Conversely, to infer necessary conditions we can be interested in devising the strongest hypotheses under which some correct run is possible.

To investigate the existence of weakest/strongest pre and post, we find convenient to focus on the validity of the four kinds of triples as shown in Figure~\ref{fig:sil:taxonomy}.
The concrete semantics is trivially a strongest (HL and NC) or weakest (IL and SIL) condition for the ``target'' property (i.e., $P$ computing backward and $Q$ forward).
However, it turns out that having a best condition on the ``source'' property is a prerogative of over-approximation, i.e., that over and under-approximation are not dual theories in this respect.
\begin{prop}[Existence of weakest conditions]\label{prop:sil:weakest-cond-existence}
	For any command $\regr\in\Reg$:
	\begin{itemize}
		\item given $Q$, there exists a weakest $P$ such that $\fwsem{\regr} P \subseteq Q$ (HL);
		\item given $P$, there exists a weakest $Q$ such that $\bwsem{\regr} Q \subseteq P$ (NC).
	\end{itemize}
\end{prop}

\begin{prop}[Non-existence of strongest conditions]\label{prop:sil:strongest-cond-non-existence}
	For any command $\regr\in\Reg$:
	\begin{itemize}
		\item for some $Q$, there is no strongest $P$ such that $\fwsem{\regr} P \supseteq Q$ (IL);
		\item for some $P$, there is no strongest $Q$ such that $\bwsem{\regr} Q \supseteq P$ (SIL).
	\end{itemize}
\end{prop}

The reason why strongest conditions may not exist for IL and SIL is that collecting semantics (both forward and backward) are additive but not co-additive. In other words, rule \hlrule{disj} is sound for all triples, while rule \hlrule{conj} is valid for HL and NC but neither for IL nor SIL, as shown in Figure~\ref{fig:sil:rules-comparison}.
This means that given two IL triples $\iltriple{P_1}{\regr}{Q}$ and $\iltriple{P_2}{\regr}{Q}$, in general $\fwsem{\regr} (P_1 \cap P_2) \nsupseteq Q$ in which case $\iltriple{P_1 \cap P_2}{\regr}{Q}$ is not valid, as shown in the following example.

\begin{example}\label{ex:sil:il-no-strongest-pre}
	Consider the program $\mathsf{r1} \eqdef x := 1$.
	The two IL triples $\iltriple{x = 0}{\mathsf{r1}}{x = 1}$ and $\iltriple{x = 10}{\mathsf{r1}}{x = 1}$ are valid, but their intersection is $\iltriple{\emptyset}{\mathsf{r1}}{x = 1}$, which is not valid.

	For SIL, consider the program $\mathsf{rnd} \eqdef \code{x := nondet()}$. Both triples $\siltriple{x = 1}{\mathsf{rnd}}{x = 0}$ and $\siltriple{x = 1}{\mathsf{rnd}}{x = 10}$ are valid, but also incomparable and minimal because $\emptyset$ is not a valid postcondition.
\end{example}

This can also be observed using the theory of adjunction. It is well known that left adjoints are additive while right adjoints are co-additive~\cite{DP02}.
The weakest precondition $\wlp$ for HL is characterized by the adjunctive property $P \subseteq \wlp[\regr](Q)$ iff $\fwsem{\regr} P \subseteq Q$ (weakest postconditions for NC are defined analogously). Since the forward (resp. backward) semantics is additive we get the existence of its right adjoint, that is exactly HL weakest precondition (resp. NC weakest postcondition).
However, a strongest precondition \textbf{sp} for IL would satisfy the adjunctive property $\textbf{sp}[\regr](Q) \subseteq P$ iff $Q \subseteq \fwsem{\regr} P$, making the non co-additive forward semantics a right adjoint. Similarly, a strongest postcondition for SIL would be a left adjoint of the backward semantics.

\subsection{Termination and Reachability}
Termination and reachability are two sides of the same coin when switching from forward to backward semantics, and over and under-approximation behave differently with respect to these notions.

For HL we can only distinguish a precondition which always causes divergence: if $\hltriple{P}{\regr}{\emptyset}$, all states in the precondition $P$ will always diverge. However, if just one state in $P$ has one terminating computation, its final state must be in $Q\neq \emptyset$, so we cannot say whether states in $P$ diverge or not. Moreover, because of the over-approximation, a non empty $Q$ does not mean there truly are finite executions, as those may be introduced by the approximation.
Dually, NC cannot say much about reachability of $Q$ unless $P$ is empty, in which case $Q$ is unreachable.

On the contrary, under-approximation offers much stronger guarantees on termination/reachability. Any IL triple $\iltriple{P}{\regr}{Q}$ ensures that all states in $Q$ are reachable (in particular, from states in $P$). Dually, a SIL triple $\siltriple{P}{\regr}{Q}$ means that all states in $P$ have a convergent computation that ends in some state in $Q$. This observation motivates the design of a forward iteration rule in IL (resp. backward in SIL): a backward (resp. forward) rule would need to prove reachability of all points in the post (resp. pre). Instead, the forward rule of IL (resp. backward rule of SIL) ensures reachability (resp. termination) by construction, as it builds $Q$ (resp. $P$) only with points known to be reachable (resp. terminating).

\section{Separation Sufficient Incorrectness Logic}\label{sec:sil:separation-sil}
We instantiate SIL to handle pointers and dynamic memory allocation, introducing Separation SIL. The goal of Separation SIL is to identify the causes of memory errors: it takes the backward under-approximation principles of SIL and combines it with the ability to deal with pointers from Separation Logic (SL)~\cite{Reynolds02,ORY01}

\subsection{Heap regular commands}
We denote by $\Regh$ the set of heap regular commands obtained by plugging the following definition of heap atomic commands in~\eqref{eq:bg:regr-def} (in \textcolor{ACMBlue}{blue} new primitives):
\begin{align*}
	\Cmdh \ni \regc ::= \; & \code{skip} \mid \code{x := a} \mid \code{b?} \mid	\textcolor{ACMBlue}{\code{x := alloc()} \mid \code{free(x)} \mid \code{x := [y]} \mid \code{[x] := y}}
\end{align*}
where we assume that \code{x} and \code{y} are syntactically distinct variables.
The command \code{x := alloc()} allocates a new memory location containing a nondeterministic value, \code{free(x)} deallocates memory, and \code{[$\cdot$]} dereferences a variable.
The syntax only allows to allocate, free and dereference single variables. To use a value from the heap in an arithmetic $\code{a} \in \AExp$ or Boolean expressions $\code{b} \in \BExp$, it must be loaded in a variable beforehand.

Given a heap command $\regr \in \Regh$, we let $\fv(\regr) \subseteq \Var$ be the set of (free) variables of $\regr$ and $\modified(\regr) \subseteq \Var$ be the set of variables modified by $\regr$. The definition of the former is standard, while the latter is defined inductively in Figure~\ref{fig:sil:regh-mod-def}. Note that \code{free(x)} and \code{[x] := y} do not modify \code{x}: they only modify the value \emph{pointed by} \code{x}, not the actual value of \code{x} (the memory address itself).

\begin{figure}[t]
	\begin{align*}
		 & \modified(\code{skip}) = \emptyset \qquad                                        &  & \modified(\code{x := a}) = \{ \code{x} \}                                \\
		 & \modified(\code{b?}) = \emptyset \qquad                                          &  & \modified(\code{x := alloc()}) = \{ \code{x} \}                          \\
		 & \modified(\code{free(x)}) = \emptyset \qquad                                     &  & \modified(\code{x := [y]}) = \{ \code{x} \}                              \\
		 & \modified(\code{[x] := y}) = \emptyset                                           &  & \modified(\regr_1; \regr_2) = \modified(\regr_1) \cup \modified(\regr_2) \\
		 & \modified(\regr_1 \regplus \regr_2) = \modified(\regr_1) \cup \modified(\regr_2) &  & \modified(\regr^{\kstar}) = \modified(\regr)
	\end{align*}
	\caption{Definition of $\modified(\regr)$.}
	\label{fig:sil:regh-mod-def}
\end{figure}

\subsection{Assertion language}
Our assertion language is derived from SL (see Section~\ref{sec:bg:sl}) and ISL~\cite{RBDDOV20}:
\begin{align*}
	\Asl \ni p, q ::= & \; \false \mid \true \mid p \land q \mid p \lor q \mid \exists x . p \mid \code{a} \asymp \code{a} \mid \emp \mid x \mapsto \code{a} \mid x \dealloc \mid p \andsep q
\end{align*}
where $\asymp \in \{ =, \neq, \le, <, \dots \}$ replaces standard comparison operators, $x \in \Var$ is a generic variable and $\code{a} \in \AExp$ is an arithmetic expression. The first six constructs describe a fragment of first-order logic, called coherent logic~\cite{BC05}, which is also the one used in bi-abduction~\cite{CDOY09}. The last four describe heaps.
$\emp$ denotes an empty heap, $x \mapsto a$ represents an heap with a single memory cell pointed by $x$ and whose content is $a$, $x \dealloc$ describes that $x$ points to a previously deallocated memory cell (it was first introduced in \cite{RBDDOV20}).
The separating conjunction $p \andsep q$ is a key feature of Separation Logics and describes an heap which can be divided in two disjoint sub-heaps, one satisfying $p$ and the other $q$.
We let $x \mapsto - \eqdef \exists v. x \mapsto v$ describe that $x$ is allocated without tracking its exact value.
Given a formula $p \in \Asl$, we call $\fv(p) \subseteq \Var$ the set of its free variables.

\subsection{Proof system}\label{sec:sil:sepsil-proof-system}

\begin{figure}[t]
	\centering
	\begin{framed}
		\hspace*{-0.6em}
		\(
		\begin{array}{cc}
			\infer[\silrule{skip}]
			{\siltriple{\emp}{\code{skip}}{\emp}}
			{}
			\;                           &
			\infer[\silrule{assign}]
			{\siltriple{q[a / x]}{\code{x := a}}{q}}
			{}
			\\[7.5pt]
			\infer[\silrule{assume}]
			{\siltriple{q \land b}{\code{b?}}{q}}
			{}
			\;                           &
			\infer[\silrule{alloc}]
			{\siltriple{\emp}{\code{x := alloc()}}{x \mapsto v}}
			{}
			\\[7.5pt]
			\infer[\silrule{free}]
			{\siltriple{x \mapsto -}{\code{free(x)}}{x \dealloc}}
			{}
			\;                           &
			\infer[\silrule{load}]
			{\siltriple{y \mapsto a \andsep q[a / x]}{\code{x := [y]}}{y \mapsto a \andsep q}}
			{x \notin \fv(a)}
			\\[7.5pt]
			\infer[\silrule{store}]
			{\siltriple{x \mapsto -}{\code{[x] := y}}{x \mapsto y}}
			{}
			\\[7.5pt]
			\hline\hline                 &                                                               \\[-2pt]
			\infer[\silrule{exists}]
			{\siltriple{\exists x. p}{\regr}{\exists x. q}}
			{\siltriple{p}{\regr}{q}     & x \notin \fv(\regr)}
			\;                           &
			\infer[\silrule{frame}]
			{\siltriple{p \andsep t}{\regr}{q \andsep t}}
			{\siltriple{p}{\regr}{q}     & \fv(t) \cap \modified(\regr) = \emptyset}
			\\[7.5pt]
			\hline\hline                 &                                                               \\[-2pt]
			\infer[\silrule{cons}]
			{\siltriple{p}{\regr}{q}}
			{p \Rightarrow p'            & \siltriple{p'}{\regr}{q'}                 & q' \Rightarrow q}
			\;                           &
			\infer[\silrule{seq}]
			{\siltriple{p}{\regr_1; \regr_2}{q}}
			{\siltriple{p}{\regr_1}{t}   & \siltriple{t}{\regr_2}{q}}
			\\[7.5pt]
			\infer[\silrule{choice}]
			{\siltriple{p_1 \lor p_2}{\regr_1 \regplus \regr_2}{q}}
			{\siltriple{p_1}{\regr_1}{q} & \siltriple{p_2}{\regr_2}{q}}
			\;                           &
			\infer[\silrule{iter}]
			{\siltriple{\exists n. q(n)}{\regr^\kstar}{q(0)}}
			{\forall n \ge 0 \;\; \siltriple{q(n+1)}{\regr}{q(n)}}
			\\[7.5pt]
			%\hline\hline & \\[-2pt]
			\infer[\silrule{empty}]
			{\siltriple{\false}{\regr}{q}}
			{}
			\;                           &
			\infer[\silrule{disj}]
			{\siltriple{p_1 \lor p_2}{\regr}{q_1 \lor q_2}}
			{\siltriple{p_1}{\regr}{q_1} & \siltriple{p_2}{\regr}{q_2}}
			\\[7.5pt]
			\infer[\silrule{iter0}]
			{\siltriple{q}{\regr^{\kstar}}{q}}
			{}
			\;                           &
			\infer[\silrule{unroll}]
			{\siltriple{p}{\regr^{\kstar}}{q}}
			{\siltriple{p}{\regr^{\kstar}; \regr}{q}}
		\end{array}
		\)
	\end{framed}
	\caption{Proof rules for Separation SIL. The first group replaces SIL rule \silrule{atom}, the second includes rules peculiar of SL, the third includes rule from SIL.}
	\label{fig:sil:separation-sil}
\end{figure}

We present the rules of Separation SIL in Figure~\ref{fig:sil:separation-sil}. $q[a / x]$ is the capture-avoiding substitution.
For the sake of presentation, we present rules without explicit error management (see Remark~\ref{rem:bg:ok-er-flags}). However, the extension is straightforward: in Section~\ref{sec:sil:separation-sil-error} we present the error rule for store and its use in Example~\ref{ex:sil:separation-sil-derivation-error}, as well as discussing the formal changes to the semantics model.

We split the rules in three groups. The first group gives the rules for atomic commands $\regc \in \Cmdh$, i.e., all instances of the SIL rule \silrule{atom}. The second one includes rules borrowed from SL, the third one from SIL.

Rule \silrule{skip} is straightforward: whatever is true before and after the \code{skip} can be added with \silrule{frame}.
Rule \silrule{assign} is Hoare's backward assignment rule~\cite{Hoare69}. Floyd's forward axiom~\cite{Floyd67} is also valid for SIL (see Section~\ref{sec:sil:rules-comparison}), but we opt for Hoare's rule because it fits better with the backward analysis of SIL.
Rule \silrule{assume} conjoins the assertion \code{b} to the postcondition: only states satisfying the Boolean guard can reach the post.
Rule \silrule{alloc} allocates a new memory location for $x$. The premise is empty: if the previous content of $x$ is needed, $x = z$ can be introduced in the premise with \silrule{cons}.
Rule \silrule{free} requires $x$ to be allocated before freeing it.
Rule \silrule{load} is similar to \silrule{assign}, with the addition of the (disjoint) $y \mapsto a$ to make sure that $y$ is allocated.
Rule \silrule{store} requires that $x$ is allocated, and updates the value it points to.
All these rules are local: thanks to \silrule{frame}, they can specify only pre and post for the modified part of the heap.

Rule \silrule{exists} allows to ``hide" local variables.
Rule \silrule{frame} is typical of separation logics~\cite{Reynolds02,RBDDOV20}: it allows to add a frame around a derivation through the separating conjunction $\andsep$, plugging the proof for a small portion of a program inside a larger heap.
In the third group, we instantiated the SIL rules from Figure~\ref{fig:sil:sil-rules} for logical formulae, by replacing set theoretical symbols (such as $\subseteq$ and $\emptyset$) with the corresponding logical symbols (such as $\Rightarrow$ and $\false$, respectively). The only notable difference is in rule \silrule{iter}, where Separation SIL uses a predicate $q(n)$ parametrized by the natural number $n \in \mathbb{N}$ and the precondition $\exists n. q(n)$ in the conclusion of the rule. This is a logical replacement for the infinite union used in SIL rule.

\subsection{Soundness}

\begin{figure}[t]
	\begin{subfigure}[t]{\linewidth}
		\centering
		\begin{align*}
			\edenot{\code{skip}} (s, h)         & \eqdef \{ (s, h) \}                                                                                    \\
			\edenot{\code{x := a}} (s, h)       & \eqdef \left\lbrace (s[x \mapsto \edenot{\code{a}} s], h) \right\rbrace                                \\
			\edenot{\code{b?}} (s, h)           & \eqdef \begin{cases*}
				                                             \left\lbrace (s, h) \right\rbrace & if $\edenot{\code{b}} s = \code{tt}$ \\
				                                             \emptyset                         & otherwise
			                                             \end{cases*}    \\
			\edenot{\code{x := alloc()}} (s, h) & \eqdef \left\lbrace (s[x \mapsto l], h[l \mapsto v]) \svert v \in \Val, \mathit{avail}(l)\right\rbrace \\
			\edenot{\code{free(x)}} (s, h)      & \eqdef
			\left\lbrace (s, h[s(x) \mapsto \delta]) \right\rbrace\quad \text{if}~h(s(x)) \in \Val                                                       \\
			\edenot{\code{x := [y]}} (s, h)     & \eqdef
			\left\lbrace (s[x \mapsto h(s(y))], h) \right\rbrace\quad \text{if}~h(s(y)) \in \Val                                                         \\
			\edenot{\code{[x] := y}} (s, h)     & \eqdef
			\left\lbrace (s, h[s(x) \mapsto s(y)]) \right\rbrace \quad \text{if}~h(s(x)) \in \Val
		\end{align*}
		\caption{Semantics of heap atomic commands, where $\mathit{avail}(l) \eqdef (l \notin \dom(h) \lor h(l) = \delta)$ and we assume that $\edenot{\regc} (s, h)\eqdef \left\lbrace \errstate \right\rbrace$ unless differently stated.}
		\label{fig:sil:ssil-model-commands}
	\end{subfigure}
	\begin{subfigure}[t]{\linewidth}
		\vspace*{1ex}
		\centering
		\begin{align*}
			 & \asldenot{a_1 \asymp a_2} \eqdef \{ (s, h) \svert \edenot{a_1} s \asymp \edenot{a_2} s \}                                          &  & \asldenot{\false} \eqdef \emptyset                         \\
			 & \asldenot{\exists x. p} \eqdef \{ (s, h) \svert \exists v \in \Val \sdot (s[x \mapsto v], h) \in \asldenot{p} \}                   &  & \asldenot{\true} \eqdef \Sigma                             \\
			 & \asldenot{x \dealloc} \eqdef \{ (s, [s(x) \mapsto \delta]) \}                                                                      &  & \asldenot{p \lor q} \eqdef \asldenot{p} \cup \asldenot{q}  \\
			 & \asldenot{x \mapsto a} \eqdef \{ (s, [s(x) \mapsto \edenot{a} s]) \}                                                               &  & \asldenot{p \land q} \eqdef \asldenot{p} \cap \asldenot{q} \\
			 & \asldenot{p \andsep q} \eqdef \{ (s, h_p \bullet h_q) \svert (s, h_p) \in \asldenot{p}, (s,h_q) \in \asldenot{q}, h_p \perp h_q \} &  & \asldenot{\emp} \eqdef \{ (s, []) \}
		\end{align*}
		\caption{Semantics of the assertion language.}
		\label{fig:sil:ssil-model-assertions}
	\end{subfigure}
	\caption{Ingredients to prove soundness of Separation SIL.}
\end{figure}

To prove soundness of Separation SIL, we give a semantic model for heap regular commands.
Fixed a finite set $\Var$ of variables and an infinite set $\Loc$ of memory locations, we define the set of values as $\Val \eqdef \setZ \uplus \Loc$ ($\uplus$ is disjoint union).
Stores $s \in \Stores$ are (total) functions $s: \Var \rightarrow \Val$; heaps $h \in \Heaps$ are partial functions $h: \Loc \rightharpoonup \Val \uplus \{ \delta \}$. If $h(l) = v \in \Val$, location $l$ is allocated and holds value $v$, if $l \notin \dom(h)$ then it is not allocated. The special value $\delta$ describes a deallocated memory location: if $h(l) = \delta$, that location was previously allocated and then deallocated.
As notation, we use $s[x \mapsto v]$ for function update, $[]$ for the empty heap and $[l \mapsto v]$ for the heap defined only on $l$ and associating value $v$ to it.
We say two heaps are disjoint, written $h_1 \perp h_2$, when $\dom(h_1) \cap \dom(h_2) = \emptyset$, and in that case we define the $\bullet$ operation as the merge of the two: $h_1 \bullet h_2$ coincides with $h_1$ on $\dom(h_1)$, with $h_2$ on $\dom(h_2)$ and it is undefined everywhere else.

Let $\Sigma = \Stores \times \Heaps$, and $\Sigma_e = \Sigma \uplus \{ \errstate \}$: states $\sigma \in \Sigma_e$ are either a pair store/heap or the error state \errstate{}.
The denotational semantics of atomic commands $\edenot{\cdot}: \Cmdh \rightarrow \wp(\Sigma_e) \rightarrow \wp(\Sigma_e)$ is in Figure~\ref{fig:sil:ssil-model-commands}. To simplify the presentation, we define it as $\edenot{\cdot}: \Cmdh \rightarrow \Sigma \rightarrow \wp(\Sigma_e)$, we let $\edenot{\regc} \errstate = \{ \errstate \}$, and we lift it to set of states by union.
Please note that evaluation of arithmetic $\code{a}$ and Boolean expressions $\code{b}$ only depends on the store since they cannot dereference variables.
We define the forward collecting semantics of heap commands $\fwsem{\cdot}: \Regh \rightarrow \wp(\Sigma_e) \rightarrow \wp(\Sigma_e)$ just as in Figure~\ref{fig:bg:regcom-sem} using the different semantics of atomic commands for $\regc \in \Cmdh$.

The semantics $\asldenot{\cdot}$ of a formula $p \in \Asl$ is a set of states in $\Sigma$, and is defined in Figure~\ref{fig:sil:ssil-model-assertions}.

We say a Separation SIL triple $\siltriple{p}{\regr}{q}$ is valid if $\bwsem{\regr} \asldenot{q} \supseteq \asldenot{p}$. To prove soundness of Separation SIL, we rely on a stronger lemma, whose proof is by induction on the derivation tree. Then, by taking $t = \emp$ and using $p \andsep \emp \equiv p$, we get the soundness of the proof system.

\begin{lemma}\label{lmm:sil:separation-sil-stronger-sound}
	Let $p, q, t \in \Asl$ and $\regr \in \Regh$. If $\vdash \siltriple{p}{\regr}{q}$ and $\fv(t) \cap \modified(\regr) = \emptyset$,
	\[
	\bwsem{\regr} \asldenot{q \andsep t} \supseteq \asldenot{p \andsep t}
	\]
\end{lemma}

\begin{corollary}[Separation SIL is sound]\label{th:sil:separation-sil-sound}
	Any provable Separation SIL triple is valid:
	\[
	\vdash \siltriple{p}{\regr}{q} \implies \vDash \siltriple{p}{\regr}{q}
	\]
\end{corollary}

\subsection{Example of Separation SIL derivation}

We show in the next example how Separation SIL proof system can infer preconditions ensuring that a provided error can happen.

\begin{example}\label{ex:separation-sil-derivation}
	Consider the the motivating example of~\cite{RBDDOV20}, encoding a use-after-free bug involving C++ vector push\_back function:

	\begin{minipage}[t]{0.4\textwidth}
		\vspace{0.5ex}
		\begin{minted}{C}
// program rclient
x := *v;
push_back(v);
*x := 1;
\end{minted}
	\end{minipage}\qquad
	\begin{minipage}[t]{0.4\textwidth}
		\vspace{0.5ex}
		\begin{minted}{C}
push_back(v) {
    if (nondet()) {
        free(*v);
        *v := alloc();
}   }
\end{minted}
		\vspace{0.5ex}
	\end{minipage}

	We encode the above program as a regular command by letting:
	\begin{equation*}
		\mathsf{rclient} \eqdef x := [v];\ (\regr_{b} \regplus \code{skip}) \qquad\qquad
		\regr_{b} \eqdef y := [v];\ \text{free}(y);\ y := \text{alloc}();\ [v] := y
	\end{equation*}

	Since our syntax does not include functions, we inline \code{push\_back}. We cannot free and allocate $*v$ directly, whence the auxiliary variable $y$. For simplicity, we do not include the last assignment \code{*x := 1} in $\mathsf{rclient}$: whenever the postcondition $x \dealloc$ holds, an error occurs after $\mathsf{rclient}$.

	We prove the Separation SIL triple
	\[
	\siltriple{v \mapsto z \andsep z \mapsto - \andsep \true}{\mathsf{rclient}}{x \dealloc \andsep \true}
	\]
	which ensures that \emph{every} state in the precondition reaches the error, thus giving (many) actual witnesses for testing and debugging purposes. Moreover, Separation SIL proof system guides the crafting of the precondition if the proof is done from the error postcondition backward.

	\begin{figure}[t]
		\begin{subfigure}[T]{0.5\textwidth}
			\footnotesize
			\bigskip
			%\vspace{1em}
			\begin{math}
				\begin{aligned}
					 & \silexact{p: v \mapsto z \andsep z \mapsto - \andsep \true}                                                              \\[-0.5em]
					 & \qquad\equiv                                                                                                             \\[-0.5em]
					 & \silexact{ v \mapsto z \andsep (z = z \lor z \dealloc) \andsep z \mapsto - \andsep \true }                               \\
					 & \quad x := [v]                                                                                                           \\
					 & \textcolor{gray}{\silexact{ \underline{v \mapsto z \andsep (x = z \lor x \dealloc)} \andsep z \mapsto - \andsep \true }} \\
					 & \silexact{(\true \andsep v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc)) \lor q}                        \\
					 & \left(
					\begin{array}{l}
							\silexact{t}               \\
							\quad y := [v];            \\
							\quad \text{free}(y);      \\
							\quad y := \text{alloc}(); \\
							\quad [v] := y             \\
							{\silexact{q}}
						\end{array}
					\right) \regplus \begin{array}{l}
						                 \silexact{x \dealloc \andsep \true} \\
						                 \quad \code{skip}                   \\
						                 \silexact{x \dealloc \andsep \true}
					                 \end{array}                                                                        \\
					 & \silexact{q: x \dealloc \andsep \true}
				\end{aligned}
			\end{math}
			\caption{Linearized derivation of the Separation SIL triple $\siltriple{p}{\mathsf{rclient}}{q}$. The omitted sub-derivation is in Figure~\ref{fig:sil:ssil-derivation:sub2}.}
			\label{fig:sil:ssil-derivation:sub1}
		\end{subfigure}
		\begin{subfigure}[T]{0.45\textwidth}
			\footnotesize
			\begin{align*}
				 & \silexact{t: \true \andsep v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc)}                            \\
				 & \quad y := [v];                                                                                                        \\
				 & \textcolor{gray}{\silexact{\true \andsep \underline{v \mapsto z \andsep y \mapsto - \andsep (x = y \lor x \dealloc)}}} \\
				 & \silexact{\true \andsep v \mapsto - \andsep y \mapsto - \andsep (x = y \lor x \dealloc)}                               \\
				 & \quad \text{free}(y);                                                                                                  \\
				 & \textcolor{gray}{\silexact{\true \andsep v \mapsto - \andsep \underline{y \dealloc} \andsep (x = y \lor x \dealloc)}}  \\
				 & \silexact{x \dealloc \andsep v \mapsto - \andsep \emp \andsep \true}                                                   \\
				 & \quad y := \text{alloc}();                                                                                             \\
				 & \textcolor{gray}{\silexact{x \dealloc \andsep v \mapsto - \andsep \underline{y \mapsto y'} \andsep \true}}             \\
				 & \silexact{x \dealloc \andsep v \mapsto - \andsep \true}                                                                \\
				 & \quad [v] := y                                                                                                         \\
				 & \textcolor{gray}{\silexact{x \dealloc \andsep \underline{v \mapsto y} \andsep \true}}                                  \\
				 & \silexact{q: x \dealloc \andsep \true}
			\end{align*}
			\caption{Linearized derivation of the Separation SIL triple $\siltriple{t}{\regr_{b}}{q}$.}
			\label{fig:sil:ssil-derivation:sub2}
		\end{subfigure}
		\caption{The full derivation of $\siltriple{p}{\mathsf{rclient}}{q}$, split in two parts. We write in \textcolor{gray}{grey} the strengthened conditions obtained using \silrule{cons}, and \underline{underline} the postcondition of the rule for the current atomic command. Everything else is a frame shared between pre and post, using \silrule{frame}.}
		\label{fig:sil:ssil-derivation}
	\end{figure}

	Let us fix the following assertions:
	\[
	p \eqdef (v \mapsto z \andsep z \mapsto - \andsep \true)
	\quad
	q \eqdef (x \dealloc \andsep \true)
	\quad
	t \eqdef (v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc) \andsep \true)
	\]

	To prove the Separation SIL triple $\siltriple{p}{\mathsf{rclient}}{q}$, we first prove the triple $\siltriple{t}{\regr_b}{q}$, whose derivation is in Figure~\ref{fig:sil:ssil-derivation:sub2}.
	Derivations are best read bottom-up: we start from the post and, for every atomic command, we find a suitable pre to apply the rule. In all cases, we strengthen the post to be able to apply the right rule: this usually means adding some constraint on the shape of the heap.
	Particularly, to apply the rule \silrule{free} we need $y$ to be deallocated, and this can happen in two different ways: either if $y = x$, since $x$ is deallocated; or if $y$ is a new name. This is captured by the disjunction $x = y \lor x \dealloc$. We remark that this can be inferred algorithmically via Lemma~\ref{lmm:sil:separation-assertion-rewrite}.

	Using the derivation in Figure~\ref{fig:sil:ssil-derivation:sub2}, we complete the proof as shown in Figure~\ref{fig:sil:ssil-derivation:sub1}. In the derivation, using rule \silrule{load} for the first assignment \code{x := [v]}, we get the pre $(v \mapsto z \andsep z \mapsto - \andsep (z = z \lor z \dealloc) \andsep \true)$, but since $z \mapsto - \andsep z \dealloc$ is not satisfiable we remove that disjunct and find $p$.

	Note the use of rule \silrule{cons} in the pre of the nondeterministic choice to remove the disjunct $(x \dealloc \andsep \true)$, effectively dropping the analysis of that program path. This correspond to IL's ability to drop paths going forward.
\end{example}

In the example, we use as error postcondition $x \dealloc \andsep \true$. It is necessary to include $(\andsep\ \true)$ because, in final reachable states, $x$ is not the only variable allocated (there are also $v$ and $y$), so the final heap should talk about them as well. Adding $(\andsep\ \true)$ is a convenient way to focus only on the part of the heap that describes the error, that is $x \dealloc$, and just leave everything else unspecified.

For the same program, the authors of~\cite{RBDDOV20} prove the ISL triple $\iltriple{v \mapsto z \andsep z \mapsto -}{\mathsf{rclient}}{v \mapsto y \andsep y \mapsto - \andsep x \dealloc}$. This proves the existence of a faulty execution, but tells nothing about which input states actually lead to the error. On the other hand, the Separation SIL triple has a more succinct post capturing the error and exposes faulty initial states.

Lastly, we remark that, while in \cite[Figure~6]{ZDS23} outcome-based separation logic proves essentially the same triple, the deduction process is quite different from SIL.
OL reasoning is forward oriented, as witnessed by the implication that concludes the proof and by the triple for the $\code{skip}$ branch, whereas Separation SIL proof system naturally guides the backward inference.

\subsection{Exit conditions in Separation SIL}\label{sec:sil:separation-sil-error}
We now briefly show how to adapt Separation SIL to handle different exit conditions. For this example, following~\cite{OHearn20}, we will consider \oktext{ok} and \ertext{er}, denoting correct and erroneous termination respectively. As discussed in Remark~\ref{rem:bg:ok-er-flags}, this correspond to use $\{ \oktext{ok}, \ertext{er} \} \times \Sigma$ as set of states instead of $\Sigma_e$. The denotational semantics of regular commands then acts as described for normal states (returning the error version of the current correct state instead of the generic $\errstate$) and as the identity on error states.

The proof system changes accordingly: all the current rules are still valid with the \oktext{ok} flag (for atoms) or a generic flag $\epsilon$ (for structural rules) in both pre and postconditions. Rules introducing error flags are added for atoms. As an example, we write below the error rule for store.
\[
\infer[\silrule{store\mbox{-}er}]
{\siltriple{\oktext{ok: x \dealloc}}{\code{[x] := y}}{\ertext{er: x \dealloc}}}
{}
\]
Moreover, the proof system is augmented with a rule for error propagation, that correspond to the fact that the semantics of programs on error states is the identity:
\[
\infer[\silrule{er\mbox{-}id}]{\siltriple{\ertext{er: q}}{\regr}{\ertext{er: q}}}{}
\]

The modified proof system is sound with respect to the modified semantics:
\begin{theorem}\label{th:sil:ssil-errors-sound}
	Any provable triple is valid:
	\[
	\vdash \siltriple{\epsilon: p}{\regr}{\epsilon': q} \implies \asldenot{\epsilon: p} \subseteq \bwsem{\regr} \asldenot{\epsilon': q}
	\]
\end{theorem}

\begin{example}\label{ex:sil:separation-sil-derivation-error}
	Consider a refinement of the program in Example~\ref{ex:separation-sil-derivation}: here we assume that \code{len} and \code{cap} are two variables associated to the vector $v$ describing its current length and capacity, respectively. We can then use them to decide the behavior of \code{push\_back}: the vector gets reallocated only if the length after the insertion would exceed the current capacity. Moreover, we assume that \code{x} is used to access the element in position $8$ of the vector, and therefore it's use after the \code{push\_back} is guarded by a check that the vector is long enough.
	Therefore, the code becomes
	\begin{align*}
		\mathsf{rclient2} & \eqdef x := [v];\ \text{if } (\code{len} >= \code{cap}) \{ \regr_{b2} \} \text{ else } \{ \code{len} := \code{len} + 1 \}; \regr_{use} \\
		\regr_{b2}        & \eqdef y := [v];\ \text{free}(y);\ y := \text{alloc}();\ [v] := y;\ \code{len} := \code{len} + 1;\ \code{cap} := \code{cap} * 2        \\
		\regr_{use}       & \eqdef \text{if } (\code{len} > 8) \{ [x] := 10 \}
	\end{align*}

	\begin{figure}
		\small
		\begin{math}
			\begin{aligned}
				 & \rlap{$\silexact{ \oktext{ok: \code{len} \ge \code{cap} \land \code{len} > 7 \land (v \mapsto z \andsep z \mapsto - \andsep \true) }} $}
				\\
				 & x := [v];                                                                                                                                &  & \silexact{ \oktext{ok: \code{len} \ge \code{cap} \land \code{len} > 7 \land (\true \andsep v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc)) }}
				\\
				 & (\code{len} \ge \code{cap})?;                                                                                                            &  & \silexact{\oktext{ok: \code{len} > 7 \land (\true \andsep v \mapsto z \andsep z \mapsto - \andsep (x = z \lor x \dealloc))}}
				\\
				 & y := [v];                                                                                                                                &  & \textcolor{gray}{\text{//}}
				\\
				 & \text{free}(y);                                                                                                                          &  & \textcolor{gray}{\text{// see Figure~\ref{fig:sil:ssil-derivation:sub2}}}
				\\
				 & y := \text{alloc}();                                                                                                                     &  & \textcolor{gray}{\text{//}}
				\\
				 & [v] := y;                                                                                                                                &  & \silexact{\oktext{ok: \code{len} + 1 > 8 \land (x \dealloc \andsep \true)}}
				\\
				 & \code{len} := \code{len} + 1;                                                                                                            &  & \silexact{\oktext{ok: \code{len} > 8 \land (x \dealloc \andsep \true)}}
				\\
				 & \code{cap} := \code{cap} * 2;                                                                                                            &  & \silexact{\oktext{ok: \code{len} > 8 \land (x \dealloc \andsep \true)}}
				\\
				 & (\code{len} > 8)?;                                                                                                                       &  & \silexact{\oktext{ok: x \dealloc \andsep \true}}
				\\
				 & [x] := 10                                                                                                                                &  & \silexact{\ertext{er: \true}}
			\end{aligned}
		\end{math}
		\caption{Sketch of the derivation of the triple for $\mathsf{rclient2}$ in Example~\ref{ex:sil:separation-sil-derivation-error}. Postconditions to each statement are written on the right of the statement itself.}
		\label{fig:sil:separation-sil-derivation-errors}
	\end{figure}

	To analyse this program, we use the error postcondition $\silexact{\ertext{er: \true}}$. For space constraints, we only consider the code path that goes through the then-branches of both if statements. The proof, linearized, is in Figure~\ref{fig:sil:separation-sil-derivation-errors}. The omitted part is analogous to the derivation in Figure~\ref{fig:sil:ssil-derivation:sub2}.

	We highlight the use of rule \silrule{store\mbox{-}er} to infer the precondition $\oktext{ok: x \dealloc \andsep \true}$ from the error postcondition $\ertext{er: \true}$ and \silrule{assume} to conjoin the boolean conditions in the preconditions of the guards. Moreover, the backward substitution of $\code{len} := \code{len} + 1$ performed by \silrule{assign} naturally propagates backward the constraint $\code{len} > 8$ to the value preceding the assignment, obtaining $\code{len} + 1 > 8$. This way, in the precondition of the whole command we explicitly find the constraints $\code{len} \ge \code{cap} \land \code{len} > 7$ on the initial values of \code{len} and \code{cap} that lead to the error.
\end{example}

\subsection{Relative completeness of Separation SIL}
The proof system in Figure~\ref{fig:sil:separation-sil} is complete for all atomic commands but \code{alloc}, because it misses the ability to refer the specific memory location that gets allocated.
The naive solution to add $x = \alpha$ in the post of \silrule{alloc} would make the frame rule unsound: it would allow to prove, for instance, the invalid triple
\[
\siltriple{\emp \andsep \alpha \mapsto -}{\code{x := alloc()}}{(x \mapsto - \land x = \alpha) \andsep \alpha \mapsto -} \text{.}
\]
Just like ISL needs the deallocated assertion in the post~\cite[\S 3]{RBDDOV20}, Separation SIL needs a ``will be allocated'' assertion in the pre. To this end, we use the $\dealloc$ assertion, and change the semantic model to only allocate a memory location that is explicitly $\delta$. We formalize this by letting $\mathit{avail}(l) \eqdef h(l) = \delta$ in Figure~\ref{fig:sil:ssil-model-commands} and replacing the axiom \silrule{alloc} with

\[
\infer[\silrule{alloc}]
{\siltriple{\beta \dealloc{}}{\code{x := alloc()}}{x = \beta \land x \mapsto v}}
{}
\]

The modified proof system is sound for this different semantics. Moreover, we can prove relative completeness~\cite[\S 4.3]{AO19} for loop-free programs:

\begin{theorem}[Relative completeness for loop-free programs]\label{th:sil:separation-sil-sequential-complete}
	Suppose to have an oracle to prove implications between formulae in $\Asl$. Let $\regr \in \Regh$ be a regular command without $\kstar$ and $p, q \in \Asl$ such that $\bwsem{\regr} \asldenot{q} \supseteq \asldenot{p}$. Then the triple $\siltriple{p}{\regr}{q}$ is provable.
\end{theorem}

The proof relies on an algorithmic rewriting of the postcondition that makes constraints on a single memory location explicit. This is given by the following lemma:

\begin{lemma}\label{lmm:sil:separation-assertion-rewrite}
	Let $q \in \Asl$ be a formula without $\exists$, and let $x'$ be a fresh variable. Then,
	\begin{enumerate}
		\item there exists a $\bar{q}$ such that $q \land (x \mapsto x' \andsep \true) \equiv x \mapsto x' \andsep \bar{q}$
		\item there exists a $\bar{q}$ such that $q \land (x \dealloc \andsep \true) \equiv x \dealloc \andsep \bar{q}$
	\end{enumerate}
\end{lemma}
\begin{proof}[Proof sketch]
	$\bar{q}$ is computed inductively on the structure of $q$ as shown in the following table (the last two columns are for points (1) and (2) of the statement, respectively):

	\begin{center}
		\begin{tabular}{r|c@{\qquad\quad}c@{\qquad\quad}}
			$q$               & $\bar{q}$ (pt. 1)                                                      & $\bar{q}$ (pt. 2)  \\
			\hline
			$z \mapsto z'$    & $z' = x' \land z = x \land \emp$                                       & $\false$           \\
			$z \dealloc{}$    & $\false$                                                               & $z = x \land \emp$ \\
			$\false$          & \multicolumn{2}{c}{$\false$}                                                                \\
			$\true$           & \multicolumn{2}{c}{$\true$}                                                                 \\
			$q_1 \land q_2$   & \multicolumn{2}{c}{$\bar{q}_1 \land \bar{q}_2$}                                             \\
			$q_1 \lor q_2$    & \multicolumn{2}{c}{$\bar{q}_1 \lor \bar{q}_2$}                                              \\
			$a_1 \asymp a_2$  & \multicolumn{2}{c}{$a_1 \asymp a_2$}                                                        \\
			$\emp$            & \multicolumn{2}{c}{$\false$}                                                                \\
			$q_1 \andsep q_2$ & \multicolumn{2}{c}{$\bar{q}_1 \andsep q_2 \lor q_1 \andsep \bar{q}_2$}
		\end{tabular}
	\end{center}

	The proof that these formulae satisfy the desired equalities are in Appendix~\ref{ch:app:sil}.
\end{proof}

Using this, we compute an assertion $t$ whose semantics is precisely the weakest possible pre $\bwsem{\regr} \asldenot{q}$ and prove the triple $\siltriple{t}{\regr}{q}$. Then, using the oracle and \silrule{cons}, the theorem follows for any $p$ that implies $t$.
Notably, this theorem shows that the weakest (possible) precondition $\bwsem{\regr} \asldenot{q}$ of loop-free programs is always expressible as an assertion $t \in \Asl$, namely $\asldenot{t} = \bwsem{\regr} \asldenot{q}$, and that it can be computed algorithmically. This result is far from trivial, as it depends on the expressiveness of the assertion language: for instance, if we add negation, the same result does not hold anymore because, even if more preconditions can be expressed, we also introduce some new posts for which the precondition is not in the assertion language.

To extend the result to loops, we can focus on single states. Note that the following result does not need the oracle: it is always possible to craft a $p$ whose proof only needs decidable implications.

\begin{theorem}[State-wise completeness]\label{th:sil:separation-sil-complete-single-state}
	Given a heap program $\regr\in \Regh$ and two states $\sigma$, $\sigma'$ such that $\sigma \in \bwsem{\regr} \sigma'$, for every assertion $q$ such that $\sigma' \in \asldenot{q}$ there exists an assertion $p$ such that $\sigma \in \asldenot{p}$ and $\siltriple{p}{\regr}{q}$ is provable in Separation SIL.
\end{theorem}

\subsection{Implementations}
The ideas that lead to SIL represent \emph{a posteriori} formalization and theoretical justification of the parallel, modular, and compositional static analysis implemented in industrial grade static analyzers for security developed and used at Meta, such as Zoncolan~\cite{DFLO19}, Mariana Trench~\cite{MarianaTrench}, and Pysa~\cite{Pysa}.
Those tools automatically find more than $50$\% of the security bugs in the Meta family of apps and many SEVs ("severe bugs" in the Meta jargon)~\cite[Figure~5]{DFLO19}.

In order to scale up to hundreds of millions of lines of code, static analyses need to be parallelizable and henceforth modular and compositional. Modularity implies that the analysis can infer \emph{meaningful} information without full knowledge of the global program. Compositionality means that the~\emph{results} of analyzing modules are good enough that one does not lose information in using the inferred triple instead of inlining the code.

The analysis implemented in the aforementioned tools is a modular backward analysis that determines which input states for a function will lead to a security error, likewise the SIL rules described in Figure~\ref{fig:sil:sil-rules}.
In particular, the analysis infers sufficient incorrectness preconditions (modularity) for callees that can be used by the callers (compositionality) to generate their incorrectness preconditions.
When the propagation of the inferred sufficient precondition reaches an attacker\hyp{}controlled input, the analysers check if that input is included in the propagated error condition.
If it is the case, then it emits an error.
The function analyses are parallelized and a strategy similar to the iteration rule of Figure~\ref{fig:sil:sil-rules} is used to compute the fixpoint in presence of mutually recursive functions.

Moreover, we have a proof-of-concept implementation of Separation SIL in OCaml. The prototype is open source and available on GitHub.\footnote{\url{https://github.com/Alex23087/Failure-SSIL-Analyser}} While the prototype is not meant to scale up to real programs, it can derive all the examples in this section and helped us gain confidence in the correctness of our results. The code exploits a routine that follows closely the relative completeness Theorem~\ref{th:sil:separation-sil-sequential-complete} by implementing Lemma~\ref{lmm:sil:separation-assertion-rewrite}.
For this implementation, we thank the students of the Laboratory for Innovative Software 2024 course: Yuri Andriaccio, Samuele Bonini, Andrea Castagna, Marco Antonio Corallo, Andrea Simone Costa, Fabio Federico, Elvis Rossi, Alessandro Scala, Matteo Simone.

\section{Summary}
In this chapter, we considered known program logics for over and under-approximation and tried to formalize the relations among them in order to asses their respective strengths and weaknesses. This led to the introduction of the novel proof system for Lisbon triples, that we dubbed Sufficient Incorrectness Logic, and to compare the four logics along several dimensions.
We also instantiated the new SIL proof system to handle pointers and memory allocation. The resulting Separation SIL is able to identify the causes of memory errors. We presented a first, simpler version of Separation SIL for which we provide a prototype implementation. We also showed how to manage explicit errors via ok/er flags, and how to modify the logic to become complete.
Comparing the logics, we recovered some known results as well as finding new connections and highlighting insights that shed a little more light on the asymmetries between over/under-approximation an forward/backward analysis. The shortest summary of our findings is that there is no silver bullet: each logic has its own strengths and use cases.
